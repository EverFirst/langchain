{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "259M-8OXmQD7"
      },
      "source": [
        "# Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LCEL이란 ?\n",
        "LangChain Expression Language의 줄임말로, 프로토타입에서 생산으로의 전환을 쉽게 지원합니다. 스트리밍 및 비동기 지원, 병렬 실행 최적화, 재시도 및 대체 방법, 중간 결과 접근, 입력/출력 스키마 등을 특징으로 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 필수 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "4Vahr4cWmPN6"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet  langchain-core langchain-community langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### OpenAI API Key 등록"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "86kvSCFwnI2s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"]      = \"sk-****************************************************\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opB3ho_4mVYC"
      },
      "source": [
        "## Basic example: prompt + model + output parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EY5sCeARyF9w",
        "outputId": "dc172b1c-51a0-4655-ff57-f1eb27bb08a0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Why don't ice creams ever get invited to parties?\\n\\nBecause they always melt under pressure!\""
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
        "model = ChatOpenAI(model=\"gpt-4\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "chain.invoke({\"topic\": \"ice cream\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DywRLOBIyu2A"
      },
      "source": [
        "### 1. Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "l-reEsksywQG"
      },
      "outputs": [],
      "source": [
        "#Prompt Message 확인하기\n",
        "prompt_value = prompt.invoke({\"topic\": \"ice cream\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcPHuOumzLvn",
        "outputId": "96102229-dfa3-4125-8900-18e52fc10500"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='tell me a short joke about ice cream')])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR2nvuFezOY0",
        "outputId": "28c129a7-4ca0-41f0-8fea-10ff2191e58b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='tell me a short joke about ice cream')]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Prompt Message 추출\n",
        "prompt_value.to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n7q27qmfzYh3",
        "outputId": "7fd9f2b2-2834-4bae-86a5-ac75e957b408"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Human: tell me a short joke about ice cream'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Prompt String 으로 content만 추출\n",
        "prompt_value.to_string()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXjXuVOUzchK"
      },
      "source": [
        "### 2. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-qGMgKBzd1B"
      },
      "outputs": [],
      "source": [
        "#Model에 Prompt 넣어서 실행\n",
        "message = model.invoke(prompt_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5LGadaNzgrG",
        "outputId": "899359bd-e55f-4bfd-bcdb-cdbdffa129d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"Why don't ice creams ever get invited to parties?\\n\\nBecause they always melt under pressure!\", response_metadata={'finish_reason': 'stop', 'logprobs': None})"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gE0TZUnqznnu",
        "outputId": "9e5f5513-26a4-4733-e524-f113afbca32b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nWhy did the ice cream go to therapy? Because it was feeling a little melon-coly.'"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai.llms import OpenAI\n",
        "\n",
        "#LLM Model Test\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
        "llm.invoke(prompt_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InH0la2Szq7I"
      },
      "source": [
        "### 3. Output parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-3liWge-zsWP",
        "outputId": "8c73b2ba-cda6-4e02-f05b-13fb4d266f78"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Why don't ice creams ever get invited to parties?\\n\\nBecause they always melt under pressure!\""
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#출력값 확인\n",
        "output_parser.invoke(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdsDLBzZzzWq"
      },
      "source": [
        "### 4. Entire Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "F1dtDW2uz0gX"
      },
      "outputs": [],
      "source": [
        "input = {\"topic\": \"ice cream\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPqs6ZUD0Db6",
        "outputId": "6b16f963-6c8e-49b2-8898-4f03bf167ab8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"Why don't ice creams ever get invited to parties?\\n\\nBecause they always drip when they're on the dance floor!\", response_metadata={'finish_reason': 'stop', 'logprobs': None})"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Chain 실행\n",
        "(prompt | model).invoke(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNp3jaDF0GrU"
      },
      "source": [
        "## RAG Search Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 필수 라이브러리 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu9APNha0KNe",
        "outputId": "3dd15f17-c6fb-4ff2-8b60-b4ff035e579f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/270.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/270.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.2/270.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip --q install langchain docarray tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpKQWwuL0UPC",
        "outputId": "062abab3-eef9-40dc-fef3-560bcae44967"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
            "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "\n",
        "#Text로 VectorRetriever 생성\n",
        "vectorstore = DocArrayInMemorySearch.from_texts(\n",
        "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
        "    embedding=OpenAIEmbeddings(),\n",
        ")\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "#Prompt 템플릿 생성\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "#모델 설정\n",
        "model = ChatOpenAI()\n",
        "\n",
        "#String 데이터 타입의 Output Parser 생성\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "#Retrieval Runnable 생성\n",
        "setup_and_retrieval = RunnableParallel(\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        ")\n",
        "\n",
        "#LCEL Chain 생성\n",
        "chain = setup_and_retrieval | prompt | model | output_parser\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hCVMZYqs0XZS",
        "outputId": "68525dcd-f633-4ef1-81f7-98f6b83f2bd2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Harrison worked at Kensho.'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Chain 실행 및 답변 확인\n",
        "chain.invoke(\"where did harrison work?\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
