{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9fa23b62",
      "metadata": {
        "id": "9fa23b62"
      },
      "source": [
        "# ReAct Agent + OpenAI Functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b76dd6ad",
      "metadata": {},
      "source": [
        "#### 필수 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "id": "354b1e04",
      "metadata": {
        "id": "354b1e04"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain langchain-openai langchain_community langchain_experimental langchain-text-splitters tiktoken pypdf faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "525ba4ba",
      "metadata": {},
      "source": [
        "#### Openai api key 등록"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "8U_lhAypNH9G",
      "metadata": {
        "id": "8U_lhAypNH9G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-**********************************************************'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "G7LgipcowSQz",
      "metadata": {
        "id": "G7LgipcowSQz"
      },
      "source": [
        "## 1.ReAct Agent\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qGP4LnO6kSHN",
      "metadata": {
        "id": "qGP4LnO6kSHN"
      },
      "source": [
        "### Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bSKLXxA2b19F",
      "metadata": {
        "id": "bSKLXxA2b19F"
      },
      "source": [
        "#### Tavily Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "Q6fkh9pYcN3S",
      "metadata": {
        "id": "Q6fkh9pYcN3S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"tvly-***********************************************\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"default\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "T40PysHVQfaH",
      "metadata": {
        "id": "T40PysHVQfaH"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "#정답 5가지 설정\n",
        "search = TavilySearchResults(k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "v1w3zvKEctOr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1w3zvKEctOr",
        "outputId": "681e7791-b2ce-49c0-fedf-4b25ba47ca31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'url': 'https://m.blog.naver.com/sh2553/223159521355',\n",
              "  'content': '사이드 메뉴를 다양하게 판매하고 있어 입이 즐겁다. 점심시간에 방문하면 웨이팅이 있을 정도로. 유명하고 맛있는 즉석 떡볶이 맛집이라. 조금 이른시간 혹은 조금 늦게 방문을 추천! 재방문 지수 : ⭐⭐⭐⭐⭐. ⬇️빨강떡볶이 후기 보러가기⬇️. https://blog ...'},\n",
              " {'url': 'https://blackbear88.tistory.com/entry/양재양재시민의숲-코스트코-근처-N번째-방문-카레-돈까스-맛집-“아르코”내돈-내산-솔직후기',\n",
              "  'content': '양재/양재시민의숲 코스트코 근처 맑은 국물이 맛있는 곰탕 맛집 \"남도나주곰탕\",내돈 내산 솔직후기 (359) 2023.09.22 잠실/잠실새내 롯데타워 고소한 치즈를 활용한 브런치 맛집 \"치즈룸&테이스팅룸\",내돈 내산 솔직후기 (349)'},\n",
              " {'url': 'https://blog.naver.com/PostView.nhn?blogId=abc204308&logNo=223241678694',\n",
              "  'content': '몽거는 양재시민의 숲에서. 도보로는 15분거리에 위치하고 있어! 주변에 이마트, 코스트코 등 큰 쇼핑센터가 있어서. 마을버스도 다니고 있어! 양재시민의숲역 카페에서 찾기 쉽지않은. 주차가능한 카페라서 차 가져오시는 분들은. 편하게 카페 이용이 가능할 것 ...'},\n",
              " {'url': 'https://www.costco.co.kr/store-finder/Yangjae',\n",
              "  'content': '06772. 서울특별시 서초구 양재대로 159. (양재동 217-6) 전화번호: 1899-9900. 이메일: member@costcokr.com. 길 찾기.'},\n",
              " {'url': 'https://moovitapp.com/index/ko/대중_교통-코스트코_양재점-서울시Seoul-site_8477366-1802',\n",
              "  'content': \"코스트코 양재점 까지 가장 가까운 역은 어디인가요? 코스트코 양재점 에 가장 가까운 노선들은 : 양재시민의숲 Yangjae Citizen's Forest 은(는) 611 미터 거리이며, 9 분 도보가 소요됩니다. 양재2동주민센터.양재꽃시장 은(는) 694 미터 거리이며, 10 분 도보가 소요됩니다.\"}]"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#테스트\n",
        "search.invoke(\"양재 시민의 숲에서 가장 가까운 코스트코는 어디인가요?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "id": "GT7lgfcsvqO4",
      "metadata": {
        "id": "GT7lgfcsvqO4"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "from langchain import hub\n",
        "\n",
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "id": "Kb8YlFe6vzLv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb8YlFe6vzLv",
        "outputId": "78f5d2bb-5a10-4f12-82bc-14d4759e29e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
              " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "execution_count": 202,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt.messages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbMt0LVOwdZf",
      "metadata": {
        "id": "fbMt0LVOwdZf"
      },
      "source": [
        "### Construct the OpenAI Functions agent\n",
        "\n",
        "**create_openai_functions_agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "id": "dAKOSa8Bv0Dg",
      "metadata": {
        "id": "dAKOSa8Bv0Dg"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_openai_functions_agent, tool\n",
        "\n",
        "#함수 에이전트 생성\n",
        "agent_tools = [search]\n",
        "agent = create_openai_functions_agent(llm, agent_tools, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "id": "yTcZ3LzNv85v",
      "metadata": {
        "id": "yTcZ3LzNv85v"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "#에이전트 실행기 생성\n",
        "agent_executor = AgentExecutor(agent=agent, tools=agent_tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "id": "FPMz0ILbv_7v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPMz0ILbv_7v",
        "outputId": "bf932639-b079-4809-e2e3-3f194e219e99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#테스트\n",
        "agent_executor.invoke({\"input\": \"hi!\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "id": "HBoH3pSnwB6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBoH3pSnwB6f",
        "outputId": "a993cff6-4464-490d-9052-c5564ee08974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `tavily_search_results_json` with `{'query': '랭체인 공식 홈페이지 주소'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.samsungsds.com/kr/insights/what-is-langchain.html', 'content': '인공지능\\n랭체인(LangChain)이란 무엇인가?\\n인쇄하기\\n이 글은 IDG의 아티클을 전재하여 제공합니다.\\n 랭체인은 간단하고 통합된 API를 노출하여 기본 LLM의 구현 세부 사항을 요약하는데, 이 API를 통해 개발자들은 코드를 크게 변경하지 않고 모델을 쉽게 교체하거나 대체할 수 있다.\\n 구독하기\\n좋아요\\nInfoWorld\\n뉴스레터 구독신청 ①\\xa0 데이터 소스\\n애플리케이션이 LLM에 대한 컨텍스트를 구축하기 위해 PDF, 웹 페이지, CSV, 관계형 데이터베이스와 같은 외부 소스에서 데이터를 검색해야 하는 경우가 있다. 오픈소스 및 상용 LLM, 벡터 데이터베이스, 데이터 소스 및 임베딩에 대한 지원은 랭체인을 개발자에게 필수적인 도구로 만들고 있다.\\n'}, {'url': 'https://www.langchain.com/', 'content': 'Join Discord\\nContribute on GitHub\\n5.3M\\nMonthly Downloads\\n67k\\nGithub Stars\\n1800+\\nContributors\\n34k+\\nApps Powered\\nReady to build?\\nGo To Docs\\nGo To Docs\\nGo To Docs\\nContact Sales\\nContact Sales\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter Chatbots\\nQ&A Over Docs\\nSummarization\\nCopilots\\nWorkflow Automation\\nDocument Analysis\\nCustom Search\\nHarness the power–and wrangle the complexity– of LLMs\\nGet from proof-of-concept to production on one platform\\nRely on a set of tools built especially for non-deterministic models\\nLeverage new cognitive architectures and battle-tested orchestration\\nThanks to our contributors and partners for making LangChain awesome\\nWhen you build with LangChain, you build alongside a community of developers advancing the frontier of what’s possible with LLMs.\\n 🦜🔗 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n🦜🔗 LangChain\\n🦜🔗 LangChain\\nLangChain Expression Language makes it easy to create custom chains.\\n Go To Docs\\nGo To Docs\\nGo To Docs\\nContact Sales\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nA complete set of powerful building blocks\\nA complete set of powerful building blocks\\n Try it out here\\nGet your LLM application from prototype to production\\nGet your LLM application from prototype to production\\nBuild context-aware, reasoning applications with LangChain’s flexible abstractions and AI-first toolkit.\\n'}, {'url': 'https://m.blog.naver.com/ilovehandson/223124167133', 'content': '\\u200b\\n스키마(4 항목)\\n모델(3항목)\\n프롬프트(4항목)\\n인덱스(4항목)\\n메모리(1항목)\\n체인(4항목)\\n에이전트(4항목)\\n스키마\\n이 섹션에서는 코드베이스 전체에서 사용되는 기본 데이터 유형과 스키마에 대해 설명합니다.\\n \\u200b\\n문서를 다음 섹션으로 나누어 설명합니다:\\n\\u200b\\n📄️ 도구(Tools)\\n언어 모델이 다른 리소스와 상호 작용하는 방식\\n\\u200b\\n언어 모델이 함수와 쉽게 상호 작용할 수 있도록 하는 함수에 대한 dodream7@naver.com\\n이 블로그\\n시맨틱 커널\\n카테고리 글\\n카테고리\\n이 블로그\\n시맨틱 커널\\n카테고리 글 \\u200b\\n이 문서 섹션은 네 개의 섹션으로 나뉩니다:\\n\\u200b\\n📄️ 프롬프트 값(PromptValue)\\n모델에 대한 입력을 나타내는 클래스입니다.\\n 에이전트 실행기는 에이전트를 호출하고,\\n액션과 액션 입력을 다시 받고,\\n해당 입력으로 액션이 참조하는 도구를 호출하고,\\n도구의 출력을 가져온 다음 모든 정보를 다시 에이전트로 전달하여\\n다음 액션을 가져오는 일을 담당합니다.\\n'}, {'url': 'https://kudositdaily.tistory.com/entry/LangChain-초보자를-위한-완벽-가이드', 'content': '태그\\n관련글\\n공지사항\\nDesigned by 티스토리\\n© Kakao Corp.\\n티스토리툴바 Kudos IT Daily\\nLangChain - 초보자를 위한 완벽 가이드\\nLangChain - 초보자를 위한 완벽 가이드\\n폭발적으로 증가하는 LLM 플랫폼\\n안녕하세요. Github 저장소의 Star의 추세를 볼 수 있는 Star History 홈페이지를 통해 랭체인 저장소의 Star의 추세를 보면 이미 60k를 넘어서 지속적으로 증가하는 것을 볼 수 있습니다. 보여드린 예제는 단편적인 예제이고, 랭체인을 검색해 보시면 랭체인을 활용한 다양한 어플리케이션 사례를 살펴보실 수 있습니다.\\n 이러한 모듈들을 잘 사용한다면 원하는 기능들을 체인처럼 엮어서 다양한 어플리케이션 개발에 활용할 수 있습니다.\\n'}, {'url': 'https://ko.wikipedia.org/wiki/랭체인', 'content': '랭체인(LangChain)은 LLM(대형 언어 모델)을 사용하여 애플리케이션 생성을 단순화하도록 설계된 프레임워크이다. 언어 모델 통합 프레임워크로서 랭체인의 사용 사례는 문서 분석 및 요약 , 챗봇 , 코드 분석 을 포함하여 일반적인 언어 모델의 사용 사례와 크게 ...'}]\u001b[0m\u001b[32;1m\u001b[1;3m랭체인의 공식 홈페이지 주소는 [https://www.langchain.com/](https://www.langchain.com/) 입니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "랭체인의 공식 홈페이지 주소는 [https://www.langchain.com/](https://www.langchain.com/) 입니다.\n"
          ]
        }
      ],
      "source": [
        "#테스트\n",
        "result = agent_executor.invoke(\n",
        "    {\"input\": \"랭체인의 공식 홈페이지 주소를 알려줘요\"}\n",
        ")\n",
        "\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N5LXGmXI5q6N",
      "metadata": {
        "id": "N5LXGmXI5q6N"
      },
      "source": [
        "**Create tool**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "id": "Ac1ICsrZ5uNG",
      "metadata": {
        "id": "Ac1ICsrZ5uNG"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "\n",
        "@tool\n",
        "def multiply(first_int: int, second_int: int) -> int:\n",
        "    \"\"\"Multiply two integers together.\"\"\"\n",
        "    return first_int * second_int\n",
        "\n",
        "@tool\n",
        "def add(first_int: int, second_int: int) -> int:\n",
        "    \"Add two integers.\"\n",
        "    return first_int + second_int\n",
        "\n",
        "\n",
        "@tool\n",
        "def exponentiate(base: int, exponent: int) -> int:\n",
        "    \"Exponentiate the base to the exponent power.\"\n",
        "    return base**exponent\n",
        "\n",
        "\n",
        "tools = [multiply, add, exponentiate]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c-qm5tW9xkWE",
      "metadata": {
        "id": "c-qm5tW9xkWE"
      },
      "source": [
        "**create_openai_tool_agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "id": "kxQfH5CZxE12",
      "metadata": {
        "id": "kxQfH5CZxE12"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "\n",
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0)\n",
        "\n",
        "tool_agent = create_openai_tools_agent(llm, tools, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "id": "-Ff8UPr1x7JY",
      "metadata": {
        "id": "-Ff8UPr1x7JY"
      },
      "outputs": [],
      "source": [
        "#툴 에이전트 실행기 생성\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "id": "5xra0PSsx-ev",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xra0PSsx-ev",
        "outputId": "12f2e346-38e0-460f-d494-501bcbc45327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `tavily_search_results_json` with `{'query': 'LangChain'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.langchain.com/langchain', 'content': 'Augment the power\\nof\\xa0LLMs with your data\\nLangChain helps connect LLMs to your company’s private sources\\nof data and APIs to create context-aware, reasoning applications.\\n Our Methods\\nReady to start shipping\\nreliable GenAI apps faster?\\nLangChain and LangSmith are critical parts of the reference\\narchitecture to get you from prototype to production. The largest community building the future of LLM apps\\nLangChain’s flexible abstractions and AI-first toolkit make it\\xa0the\\xa0#1\\xa0choice for developers when building with GenAI.\\n Why choose LangChain?\\nLangChain is easy to get started with and\\xa0gives\\xa0you choice, flexibility, and power as\\xa0you scale.\\n Get customizability and control with a durable runtime baked in\\nLangChain Expression Language (LCEL) lets you build your app in a truly composable way, allowing you to customize it as you see fit.'}, {'url': 'https://github.com/langchain-ai/langchain', 'content': 'About\\n⚡ Building applications with LLMs through composability ⚡\\nResources\\nLicense\\nCode of conduct\\nSecurity policy\\nStars\\nWatchers\\nForks\\nReleases\\n291\\nPackages\\n0\\nUsed by 39k\\nContributors\\n1,848\\nLanguages\\nFooter\\nFooter navigation Latest commit\\nGit stats\\nFiles\\nREADME.md\\n🦜️🔗 LangChain\\n⚡ Building applications with LLMs through composability ⚡\\nLooking for the JS/TS library? ⚡ Building applications with LLMs through composability ⚡\\nLicense\\nlangchain-ai/langchain\\nName already in use\\nUse Git or checkout with SVN using the web URL.\\n 📖 Documentation\\nPlease see here for full documentation, which includes:\\n💁 Contributing\\nAs an open-source project in a rapidly developing field, we are extremely open to contributions, whether it be in the form of a new feature, improved infrastructure, or better documentation.\\n What can you build with LangChain?\\n❓ Retrieval augmented generation\\n💬 Analyzing structured data\\n🤖 Chatbots\\nAnd much more!'}, {'url': 'https://www.langchain.com/', 'content': 'Join Discord\\nContribute on GitHub\\n5.3M\\nMonthly Downloads\\n67k\\nGithub Stars\\n1800+\\nContributors\\n34k+\\nApps Powered\\nReady to build?\\nGo To Docs\\nGo To Docs\\nGo To Docs\\nContact Sales\\nContact Sales\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter Chatbots\\nQ&A Over Docs\\nSummarization\\nCopilots\\nWorkflow Automation\\nDocument Analysis\\nCustom Search\\nHarness the power–and wrangle the complexity– of LLMs\\nGet from proof-of-concept to production on one platform\\nRely on a set of tools built especially for non-deterministic models\\nLeverage new cognitive architectures and battle-tested orchestration\\nThanks to our contributors and partners for making LangChain awesome\\nWhen you build with LangChain, you build alongside a community of developers advancing the frontier of what’s possible with LLMs.\\n 🦜🔗 LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\n🦜🔗 LangChain\\n🦜🔗 LangChain\\nLangChain Expression Language makes it easy to create custom chains.\\n Go To Docs\\nGo To Docs\\nGo To Docs\\nContact Sales\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nA complete set of powerful building blocks\\nA complete set of powerful building blocks\\n Try it out here\\nGet your LLM application from prototype to production\\nGet your LLM application from prototype to production\\nBuild context-aware, reasoning applications with LangChain’s flexible abstractions and AI-first toolkit.\\n'}, {'url': 'https://en.wikipedia.org/wiki/LangChain', 'content': 'In October 2023 LangChain introduced LangServe, a deployment tool designed to facilitate the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[6] to store and retrieve vector embeddings; Weaviate vector database[7] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered popularity, with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project\\'s Discord server, many YouTube tutorials, and meetups in San Francisco and London. As of April 2023, it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal links[edit]'}, {'url': 'https://www.ibm.com/topics/langchain', 'content': 'Applications made with LangChain provide great utility for a variety of use cases, from straightforward question-answering and text generation tasks to more complex solutions that use an LLM as a “reasoning engine.”\\nTrain, validate, tune and deploy generative AI, foundation models and machine learning capabilities with ease and build AI applications in a fraction of the time with a fraction of the data.\\n When building a chain for an agent, inputs include:\\nDespite their heralded power and versatility, LLMs have important limitations: namely, a lack of up-to-date information, a lack of domain-specific expertise and a general difficulty with math.\\nLangChain tools\\xa0(link resides outside ibm.com) are a set of functions that empower LangChain agents to interact with real-world information in order to expand or improve the services it can provide. Launched by Harrison Chase in October 2022, LangChain enjoyed a meteoric rise to prominence: as of June 2023, it was the single fastest-growing open source project on Github.1 Coinciding with the momentous launch of OpenAI’s ChatGPT the following month, LangChain has played a significant role in making generative AI more accessible to enthusiasts in the wake of its widespread popularity.\\n Reimagine how you work with\\xa0AI: our diverse, global team of more than 20,000 AI\\xa0experts can help you quickly and confidently\\xa0design and scale AI and automation across your\\xa0business, working across our own IBM\\xa0watsonx\\xa0technology\\xa0and an open ecosystem of partners to deliver any\\xa0AI model, on any cloud, guided by ethics and trust.\\n While it’s the GPT model that interprets the user’s input and composes a natural language response, it’s the application that (among other things) provides an interface for the user to type and read and a UX design that governs the chatbot experience.'}]\u001b[0m\u001b[32;1m\u001b[1;3mLangChain is a platform that helps connect Large Language Models (LLMs) to private sources of data and APIs to create context-aware, reasoning applications. It provides developers with flexible abstractions and an AI-first toolkit to build with GenAI. LangChain offers customizability, control, and a durable runtime, making it easy to get started and scale applications. LangChain Expression Language (LCEL) allows developers to build apps in a composable way and customize them as needed. LangChain was launched in October 2022 as an open-source project and has gained popularity for its capabilities in document analysis and summarization, chatbots, and code analysis. It has integrations with various systems and tools to support a wide range of use cases.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'what is LangChain?',\n",
              " 'output': 'LangChain is a platform that helps connect Large Language Models (LLMs) to private sources of data and APIs to create context-aware, reasoning applications. It provides developers with flexible abstractions and an AI-first toolkit to build with GenAI. LangChain offers customizability, control, and a durable runtime, making it easy to get started and scale applications. LangChain Expression Language (LCEL) allows developers to build apps in a composable way and customize them as needed. LangChain was launched in October 2022 as an open-source project and has gained popularity for its capabilities in document analysis and summarization, chatbots, and code analysis. It has integrations with various systems and tools to support a wide range of use cases.'}"
            ]
          },
          "execution_count": 214,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#테스트\n",
        "agent_executor.invoke({\"input\": \"what is LangChain?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "id": "uNfBVMyX50JO",
      "metadata": {
        "id": "uNfBVMyX50JO"
      },
      "outputs": [],
      "source": [
        "# Choose the LLM that will drive the agent\n",
        "# Only certain models support this\n",
        "model = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "\n",
        "# Construct the OpenAI Tools agent\n",
        "agent = create_openai_tools_agent(model, tools, prompt)\n",
        "\n",
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "id": "bsJ2vqZ16Gln",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsJ2vqZ16Gln",
        "outputId": "c05496ce-4b01-4d07-a502-fa5072563168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `exponentiate` with `{'base': 3, 'exponent': 5}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m243\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `add` with `{'first_int': 12, 'second_int': 3}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m15\u001b[0m\u001b[32;1m\u001b[1;3mAre followup questions needed here: No.\n",
            "Intermediate answer: 3 to the fifth power is 243. The sum of twelve and three is 15.\n",
            "Follow up: Multiply 243 by 15.\n",
            "Intermediate answer: 243 multiplied by 15 is 3645.\n",
            "Follow up: Square 3645.\n",
            "Intermediate answer: The square of 3645 is 13302025.\n",
            "So the final answer is: 13302025\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result',\n",
              " 'output': 'Are followup questions needed here: No.\\nIntermediate answer: 3 to the fifth power is 243. The sum of twelve and three is 15.\\nFollow up: Multiply 243 by 15.\\nIntermediate answer: 243 multiplied by 15 is 3645.\\nFollow up: Square 3645.\\nIntermediate answer: The square of 3645 is 13302025.\\nSo the final answer is: 13302025'}"
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result\"\n",
        "    }\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
