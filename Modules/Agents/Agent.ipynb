{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9fa23b62",
      "metadata": {
        "id": "9fa23b62"
      },
      "source": [
        "# Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6736f2f7",
      "metadata": {},
      "source": [
        "#### 필수 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "id": "354b1e04",
      "metadata": {
        "id": "354b1e04"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain langchain-openai langchain_community langchain_experimental langchain-text-splitters tiktoken pypdf faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7924b76e",
      "metadata": {},
      "source": [
        "#### OpenAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "8U_lhAypNH9G",
      "metadata": {
        "id": "8U_lhAypNH9G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-**********************************************************'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qGP4LnO6kSHN",
      "metadata": {
        "id": "qGP4LnO6kSHN"
      },
      "source": [
        "## Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bSKLXxA2b19F",
      "metadata": {
        "id": "bSKLXxA2b19F"
      },
      "source": [
        "### Tavily Search"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a4719bd",
      "metadata": {},
      "source": [
        "#### tavily serch api key 등록"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "Q6fkh9pYcN3S",
      "metadata": {
        "id": "Q6fkh9pYcN3S"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"tvly-***********************************************\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"default\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "T40PysHVQfaH",
      "metadata": {
        "id": "T40PysHVQfaH"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "#Tavily search 테스트 \n",
        "#k 는 검색 결과 개수\n",
        "search = TavilySearchResults(k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "v1w3zvKEctOr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1w3zvKEctOr",
        "outputId": "681e7791-b2ce-49c0-fedf-4b25ba47ca31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'url': 'https://m.blog.naver.com/sh2553/223159521355',\n",
              "  'content': '사이드 메뉴를 다양하게 판매하고 있어 입이 즐겁다. 점심시간에 방문하면 웨이팅이 있을 정도로. 유명하고 맛있는 즉석 떡볶이 맛집이라. 조금 이른시간 혹은 조금 늦게 방문을 추천! 재방문 지수 : ⭐⭐⭐⭐⭐. ⬇️빨강떡볶이 후기 보러가기⬇️. https://blog ...'},\n",
              " {'url': 'https://blackbear88.tistory.com/entry/양재양재시민의숲-코스트코-근처-N번째-방문-카레-돈까스-맛집-“아르코”내돈-내산-솔직후기',\n",
              "  'content': '양재/양재시민의숲 코스트코 근처 맑은 국물이 맛있는 곰탕 맛집 \"남도나주곰탕\",내돈 내산 솔직후기 (359) 2023.09.22 잠실/잠실새내 롯데타워 고소한 치즈를 활용한 브런치 맛집 \"치즈룸&테이스팅룸\",내돈 내산 솔직후기 (349)'},\n",
              " {'url': 'https://blog.naver.com/PostView.nhn?blogId=abc204308&logNo=223241678694',\n",
              "  'content': '몽거는 양재시민의 숲에서. 도보로는 15분거리에 위치하고 있어! 주변에 이마트, 코스트코 등 큰 쇼핑센터가 있어서. 마을버스도 다니고 있어! 양재시민의숲역 카페에서 찾기 쉽지않은. 주차가능한 카페라서 차 가져오시는 분들은. 편하게 카페 이용이 가능할 것 ...'},\n",
              " {'url': 'https://www.costco.co.kr/store-finder/Yangjae',\n",
              "  'content': '06772. 서울특별시 서초구 양재대로 159. (양재동 217-6) 전화번호: 1899-9900. 이메일: member@costcokr.com. 길 찾기.'},\n",
              " {'url': 'https://moovitapp.com/index/ko/대중_교통-코스트코_양재점-서울시Seoul-site_8477366-1802',\n",
              "  'content': \"코스트코 양재점 까지 가장 가까운 역은 어디인가요? 코스트코 양재점 에 가장 가까운 노선들은 : 양재시민의숲 Yangjae Citizen's Forest 은(는) 611 미터 거리이며, 9 분 도보가 소요됩니다. 양재2동주민센터.양재꽃시장 은(는) 694 미터 거리이며, 10 분 도보가 소요됩니다.\"}]"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# search 결과\n",
        "search.invoke(\"양재 시민의 숲에서 가장 가까운 코스트코는 어디인가요?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GzkaxJSVdGka",
      "metadata": {
        "id": "GzkaxJSVdGka"
      },
      "source": [
        "## PDF - Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "id": "9J6EPTNydMTx",
      "metadata": {
        "id": "9J6EPTNydMTx"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "#load pdf\n",
        "loader = PyPDFLoader(\"/content/layout-parser-readthedocs-io-en-latest.pdf\")\n",
        "\n",
        "#text split 생성\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "# pdf에 split 적용\n",
        "split_docs = loader.load_and_split(text_splitter)\n",
        "\n",
        "#vector db에 데이터 저장\n",
        "vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
        "\n",
        "#검색기 생성\n",
        "retriever = vector.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "id": "ogddPcyxeRLp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogddPcyxeRLp",
        "outputId": "e32c99e1-d8be-4d43-9a5d-994996f97216"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Layout Parser, Release 0.3.2\\n42 Chapter 6. Layout Elements', metadata={'source': '/content/layout-parser-readthedocs-io-en-latest.pdf', 'page': 45}),\n",
              " Document(page_content='5.2 Loading and visualizing layouts using Layout-Parser . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n5.3 Model Predictions on loaded data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\n6 Layout Elements 27\\n6.1 Coordinate System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n6.2 TextBlock . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n6.3 Layout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\\n7 Shape Operations 43\\n7.1 Theunion Operation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\n7.2 Theintersect Operation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\n7.3 Problems related to the Quadrilateral Class . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\n8 Text Recognition Tool 47', metadata={'source': '/content/layout-parser-readthedocs-io-en-latest.pdf', 'page': 2}),\n",
              " Document(page_content='CHAPTER\\nSEVEN\\nSHAPE OPERATIONS\\n[BETA: the API and behavior willbe changed in the future.]\\nStarting from v0.2, Layout Parser provides supports for two types of shape operations, union andintersection ,\\nacross allBaseCoordElement s andTextBlock . We’ve made some design choices to construct a set of general-\\nized APIs across different shape classes, detailed as follows:\\n43', metadata={'source': '/content/layout-parser-readthedocs-io-en-latest.pdf', 'page': 46}),\n",
              " Document(page_content='Layout Parser\\nRelease 0.3.2\\nLayout Parser Contributors\\nApr 02, 2022', metadata={'source': '/content/layout-parser-readthedocs-io-en-latest.pdf', 'page': 0})]"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#input값에 대한 유사 정보 검색 테스트 \n",
        "retriever.get_relevant_documents(\n",
        "    \"layout element에 대해서 설명해줘\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "H32rXUotev6g",
      "metadata": {
        "id": "H32rXUotev6g"
      },
      "outputs": [],
      "source": [
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "#검색기를 tool로 변환\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    name=\"pdf_search\",\n",
        "    description=\"PDF에 관련된 질문은 이 도구를 사용해야 합니다!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "C9RO9CFTftkb",
      "metadata": {
        "id": "C9RO9CFTftkb"
      },
      "outputs": [],
      "source": [
        "#tool을 리스트로 변환\n",
        "tools = [search, retriever_tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "DH2fQArnfxhp",
      "metadata": {
        "id": "DH2fQArnfxhp"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "#llm 모델 생성\n",
        "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a78b7b7e",
      "metadata": {},
      "source": [
        "#### 필수 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "id": "Tz1XDCu-gEAB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tz1XDCu-gEAB",
        "outputId": "c46aa628-e800-4c69-9de0-46af07646808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchainhub in /usr/local/lib/python3.10/dist-packages (0.1.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.31.0)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.31.0.20240311)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchainhub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "id": "HPa5KYKQf09w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPa5KYKQf09w",
        "outputId": "0bc05ff3-b37e-4bcd-cf98-2b9c23278343"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
              " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "execution_count": 181,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import hub\n",
        "\n",
        "#Hub로부터 Prompt 다운로드 \n",
        "#https://smith.langchain.com/hub?ref=blog.langchain.dev\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "#프롬프트 확인\n",
        "prompt.messages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MykYSrMjgyhD",
      "metadata": {
        "id": "MykYSrMjgyhD"
      },
      "source": [
        "###**Running the agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "id": "JFuIhSqtgOBI",
      "metadata": {
        "id": "JFuIhSqtgOBI"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_openai_functions_agent\n",
        "\n",
        "#OpenAI Function Agent 생성 \n",
        "agent = create_openai_functions_agent(llm, tools, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "id": "siXbNSdwgj0q",
      "metadata": {
        "id": "siXbNSdwgj0q"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "#Agent 실행기 생성\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "id": "6xPEDjXlgUHF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xPEDjXlgUHF",
        "outputId": "f46b8f98-a6b6-4413-919a-3d79f1da112a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mOCR (Optical Character Recognition)을 사용하여 테이블을 파싱하는 과정은 이미지나 PDF 내의 텍스트를 추출하고, 이를 구조화된 형태로 변환하는 작업을 포함합니다. 테이블 파싱은 특히 데이터가 열과 행으로 구성된 테이블 형태일 때 유용합니다. 다음은 OCR을 사용하여 테이블을 파싱하는 기본적인 단계입니다:\n",
            "\n",
            "1. **이미지 준비**: 파싱할 문서나 이미지를 준비합니다. 이미지의 품질이 좋을수록 OCR의 정확도가 높아집니다. 필요한 경우 이미지의 명암, 대비, 해상도를 조정하여 품질을 개선할 수 있습니다.\n",
            "\n",
            "2. **OCR 엔진 선택**: Tesseract, Google Cloud Vision API, Amazon Textract 등 다양한 OCR 엔진 중에서 선택할 수 있습니다. 각 엔진마다 특성과 성능이 다르므로, 요구사항에 맞는 엔진을 선택하는 것이 중요합니다.\n",
            "\n",
            "3. **텍스트 추출**: 선택한 OCR 엔진을 사용하여 이미지에서 텍스트를 추출합니다. 이 과정에서 엔진은 이미지 내의 문자를 인식하고, 이를 디지털 텍스트로 변환합니다.\n",
            "\n",
            "4. **테이블 구조 인식**: 추출된 텍스트 중에서 테이블 구조를 인식합니다. 일부 OCR 엔진은 테이블 구조를 자동으로 인식하는 기능을 제공하지만, 그렇지 않은 경우에는 텍스트의 위치 정보를 사용하여 수동으로 테이블 구조를 재구성해야 할 수도 있습니다.\n",
            "\n",
            "5. **데이터 정제 및 변환**: 테이블 구조를 인식한 후, 데이터를 정제하고 필요한 형식으로 변환합니다. 이 과정에서 불필요한 공백 제거, 열과 행의 정렬, 데이터 형식 변환 등이 포함될 수 있습니다.\n",
            "\n",
            "6. **데이터 저장 및 활용**: 파싱된 테이블 데이터를 데이터베이스, 스프레드시트, 또는 다른 원하는 형식으로 저장합니다. 저장된 데이터는 분석, 보고서 작성, 데이터 시각화 등 다양한 목적으로 활용할 수 있습니다.\n",
            "\n",
            "OCR을 사용한 테이블 파싱은 복잡한 과정일 수 있으며, 특히 테이블의 구조가 복잡하거나 이미지의 품질이 낮은 경우에는 정확도가 떨어질 수 있습니다. 따라서, 가능한 한 이미지의 품질을 높이고, 정확한 OCR 엔진을 선택하는 것이 중요합니다. 또한, 후처리 과정에서의 데이터 정제와 변환 작업을 통해 최종 결과의 품질을 개선할 수 있습니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "답변: OCR (Optical Character Recognition)을 사용하여 테이블을 파싱하는 과정은 이미지나 PDF 내의 텍스트를 추출하고, 이를 구조화된 형태로 변환하는 작업을 포함합니다. 테이블 파싱은 특히 데이터가 열과 행으로 구성된 테이블 형태일 때 유용합니다. 다음은 OCR을 사용하여 테이블을 파싱하는 기본적인 단계입니다:\n",
            "\n",
            "1. **이미지 준비**: 파싱할 문서나 이미지를 준비합니다. 이미지의 품질이 좋을수록 OCR의 정확도가 높아집니다. 필요한 경우 이미지의 명암, 대비, 해상도를 조정하여 품질을 개선할 수 있습니다.\n",
            "\n",
            "2. **OCR 엔진 선택**: Tesseract, Google Cloud Vision API, Amazon Textract 등 다양한 OCR 엔진 중에서 선택할 수 있습니다. 각 엔진마다 특성과 성능이 다르므로, 요구사항에 맞는 엔진을 선택하는 것이 중요합니다.\n",
            "\n",
            "3. **텍스트 추출**: 선택한 OCR 엔진을 사용하여 이미지에서 텍스트를 추출합니다. 이 과정에서 엔진은 이미지 내의 문자를 인식하고, 이를 디지털 텍스트로 변환합니다.\n",
            "\n",
            "4. **테이블 구조 인식**: 추출된 텍스트 중에서 테이블 구조를 인식합니다. 일부 OCR 엔진은 테이블 구조를 자동으로 인식하는 기능을 제공하지만, 그렇지 않은 경우에는 텍스트의 위치 정보를 사용하여 수동으로 테이블 구조를 재구성해야 할 수도 있습니다.\n",
            "\n",
            "5. **데이터 정제 및 변환**: 테이블 구조를 인식한 후, 데이터를 정제하고 필요한 형식으로 변환합니다. 이 과정에서 불필요한 공백 제거, 열과 행의 정렬, 데이터 형식 변환 등이 포함될 수 있습니다.\n",
            "\n",
            "6. **데이터 저장 및 활용**: 파싱된 테이블 데이터를 데이터베이스, 스프레드시트, 또는 다른 원하는 형식으로 저장합니다. 저장된 데이터는 분석, 보고서 작성, 데이터 시각화 등 다양한 목적으로 활용할 수 있습니다.\n",
            "\n",
            "OCR을 사용한 테이블 파싱은 복잡한 과정일 수 있으며, 특히 테이블의 구조가 복잡하거나 이미지의 품질이 낮은 경우에는 정확도가 떨어질 수 있습니다. 따라서, 가능한 한 이미지의 품질을 높이고, 정확한 OCR 엔진을 선택하는 것이 중요합니다. 또한, 후처리 과정에서의 데이터 정제와 변환 작업을 통해 최종 결과의 품질을 개선할 수 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# agent 실행기 실행 및 답변 출력\n",
        "response = agent_executor.invoke({\"input\": \"OCR 테이블 파싱하는 방법을 알려주세요\"})\n",
        "print(f'답변: {response[\"output\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TKT3b_7ghGCu",
      "metadata": {
        "id": "TKT3b_7ghGCu"
      },
      "source": [
        "### Agent Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "id": "NDL3pAs6hY7m",
      "metadata": {
        "id": "NDL3pAs6hY7m"
      },
      "outputs": [],
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "#채팅 history 생성\n",
        "message_history = ChatMessageHistory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "id": "XNpdnb-6heFm",
      "metadata": {
        "id": "XNpdnb-6heFm"
      },
      "outputs": [],
      "source": [
        "#RunnableWithMessageHistory 모듈로 채팅 히스토리 에이전트 생성\n",
        "#lambda로 message_history 의 번호를 세션값으로 가져옴\n",
        "agent_with_chat_history = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    lambda session_id: message_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "id": "Vrg4Czffhltc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrg4Czffhltc",
        "outputId": "dd65970d-4d7b-4dad-80d0-581c7cc35240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mHi DunnDunn! It's great to meet you too. How can I assist you today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "답변: Hi DunnDunn! It's great to meet you too. How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "# agent 에 대화별 세션 아이디를 부여하여 실행 및 답변 확인\n",
        "response = agent_with_chat_history.invoke(\n",
        "    {\"input\": \"Hi! I'm DunnDunn. Glad to meet you.\"},\n",
        "    config={\"configurable\": {\"session_id\": \"MyTestSessionID\"}},\n",
        ")\n",
        "print(f\"답변: {response['output']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "id": "5Yf80eKehvll",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Yf80eKehvll",
        "outputId": "90878503-0b84-4616-8496-2d6667986e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mYour name is DunnDunn. How can I assist you further today?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "답변: Your name is DunnDunn. How can I assist you further today?\n"
          ]
        }
      ],
      "source": [
        "# 한 번 더 테스트\n",
        "response = agent_with_chat_history.invoke(\n",
        "    {\"input\": \"What's my name?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"MyTestSessionID\"}},\n",
        ")\n",
        "print(f\"답변: {response['output']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "id": "Fv__iyzKh1on",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv__iyzKh1on",
        "outputId": "d7059d5a-ad99-40a4-f218-3b311164b40a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `tavily_search_results_json` with `{'query': '양재 시민의 숲 가장 가까운 코스트코'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://namu.wiki/w/코스트코 양재점', 'content': '코스트코 옆에는 이마트 양재점, 하나로마트 양재점 하이브랜드, 서울 오토갤러리, nh농협은행, 쌍용차, 더케이 서울호텔까지 있는 혼잡한 도로라서 코스트코 진입 차량 전용 차로까지 있다. 엄청 붐비기 때문에 주말이나 설, 추석 같은 명절 대목에는 바로 ...'}, {'url': 'https://moovitapp.com/index/ko/대중_교통-코스트코_양재점-서울시Seoul-site_8477366-1802', 'content': \"코스트코 양재점 까지 가장 가까운 역은 어디인가요? 코스트코 양재점 에 가장 가까운 노선들은 : 양재시민의숲 Yangjae Citizen's Forest 은(는) 611 미터 거리이며, 9 분 도보가 소요됩니다. 양재2동주민센터.양재꽃시장 은(는) 694 미터 거리이며, 10 분 도보가 소요됩니다.\"}, {'url': 'https://www.costco.co.kr/store-finder/Yangjae', 'content': 'Yangjae/South Korea/853에서 코스트코 쇼핑하기 ... 서울특별시 서초구 양재대로 159 (양재동 217-6) 전화번호: 1899-9900 이메일: member@costcokr.com'}, {'url': 'https://blog.naver.com/PostView.nhn?blogId=abc204308&logNo=223241678694', 'content': '몽거는 양재시민의 숲에서. 도보로는 15분거리에 위치하고 있어! 주변에 이마트, 코스트코 등 큰 쇼핑센터가 있어서. 마을버스도 다니고 있어! 양재시민의숲역 카페에서 찾기 쉽지않은. 주차가능한 카페라서 차 가져오시는 분들은. 편하게 카페 이용이 가능할 것 ...'}, {'url': 'https://blog.naver.com/PostView.naver?blogId=mxxjx_o_&logNo=223287961287', 'content': '서울 양재시민의 숲 코스트코 카페 레포소 여러분 오랜만이에요!! 시험기간 및 번아웃을 극복하고 왔답니당...'}]\u001b[0m\u001b[32;1m\u001b[1;3m양재 시민의 숲에서 가장 가까운 코스트코는 **코스트코 양재점**입니다. 양재시민의숲역에서 도보로 약 9분 거리에 위치해 있으며, 주소는 **서울특별시 서초구 양재대로 159 (양재동 217-6)** 입니다. [코스트코 양재점 정보 바로가기](https://www.costco.co.kr/store-finder/Yangjae)\n",
            "\n",
            "더 필요한 정보가 있으시면 알려주세요!\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "답변: 양재 시민의 숲에서 가장 가까운 코스트코는 **코스트코 양재점**입니다. 양재시민의숲역에서 도보로 약 9분 거리에 위치해 있으며, 주소는 **서울특별시 서초구 양재대로 159 (양재동 217-6)** 입니다. [코스트코 양재점 정보 바로가기](https://www.costco.co.kr/store-finder/Yangjae)\n",
            "\n",
            "더 필요한 정보가 있으시면 알려주세요!\n"
          ]
        }
      ],
      "source": [
        "# 동일한 세션아이디로 테스트\n",
        "response = agent_with_chat_history.invoke(\n",
        "    {\"input\": \"양재 시민의 숲에서 가장 가까운 코스트코는 어디인가요?\"},\n",
        "     config={\"configurable\": {\"session_id\": \"MyTestSessionID\"}},\n",
        ")\n",
        "print(f\"답변: {response['output']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "id": "heyhvlO-iAAW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heyhvlO-iAAW",
        "outputId": "5aeeebd4-c4c6-40f4-9f3b-707d28ae4880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mOCR (Optical Character Recognition)을 사용하여 테이블을 파싱하는 과정은 이미지나 스캔된 문서 내의 텍스트를 추출하고, 이를 구조화된 데이터 형태로 변환하는 작업을 포함합니다. 다음은 OCR을 사용하여 테이블을 파싱하는 기본적인 단계입니다:\n",
            "\n",
            "1. **이미지 준비**: 파싱할 테이블이 포함된 이미지나 문서를 준비합니다. 이미지의 품질이 좋을수록 OCR의 정확도가 높아집니다.\n",
            "\n",
            "2. **OCR 엔진 선택**: Tesseract, Google Vision API, Microsoft Azure OCR 등 다양한 OCR 엔진 중에서 선택합니다. 각 엔진마다 특성과 성능이 다르므로, 요구사항에 맞는 엔진을 선택하는 것이 중요합니다.\n",
            "\n",
            "3. **텍스트 추출**: 선택한 OCR 엔진을 사용하여 이미지에서 텍스트를 추출합니다. 이 과정에서 엔진은 이미지 내의 문자를 인식하고, 이를 디지털 텍스트로 변환합니다.\n",
            "\n",
            "4. **테이블 구조 인식**: 추출된 텍스트 중에서 테이블 구조를 인식합니다. 일부 OCR 엔진은 테이블 구조를 자동으로 인식하는 기능을 제공하지만, 그렇지 않은 경우에는 텍스트의 위치 정보를 사용하여 수동으로 테이블 구조를 재구성해야 할 수 있습니다.\n",
            "\n",
            "5. **데이터 정제 및 변환**: 테이블 구조를 인식한 후, 필요에 따라 데이터를 정제하고 원하는 형식으로 변환합니다. 예를 들어, 불필요한 공백을 제거하거나, 특정 열의 데이터를 숫자 형태로 변환하는 등의 작업을 수행할 수 있습니다.\n",
            "\n",
            "6. **데이터 저장**: 파싱된 테이블 데이터를 데이터베이스, CSV 파일, JSON 파일 등 원하는 형식으로 저장합니다.\n",
            "\n",
            "OCR을 사용한 테이블 파싱은 복잡한 테이블 구조나 낮은 이미지 품질로 인해 어려움을 겪을 수 있습니다. 따라서, 고급 OCR 기술이나 추가적인 이미지 전처리 기술을 적용하여 정확도를 높일 수 있습니다.\n",
            "\n",
            "실제 구현에 있어서는 사용하고자 하는 OCR 엔진의 문서와 예제 코드를 참고하는 것이 도움이 됩니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "답변: OCR (Optical Character Recognition)을 사용하여 테이블을 파싱하는 과정은 이미지나 스캔된 문서 내의 텍스트를 추출하고, 이를 구조화된 데이터 형태로 변환하는 작업을 포함합니다. 다음은 OCR을 사용하여 테이블을 파싱하는 기본적인 단계입니다:\n",
            "\n",
            "1. **이미지 준비**: 파싱할 테이블이 포함된 이미지나 문서를 준비합니다. 이미지의 품질이 좋을수록 OCR의 정확도가 높아집니다.\n",
            "\n",
            "2. **OCR 엔진 선택**: Tesseract, Google Vision API, Microsoft Azure OCR 등 다양한 OCR 엔진 중에서 선택합니다. 각 엔진마다 특성과 성능이 다르므로, 요구사항에 맞는 엔진을 선택하는 것이 중요합니다.\n",
            "\n",
            "3. **텍스트 추출**: 선택한 OCR 엔진을 사용하여 이미지에서 텍스트를 추출합니다. 이 과정에서 엔진은 이미지 내의 문자를 인식하고, 이를 디지털 텍스트로 변환합니다.\n",
            "\n",
            "4. **테이블 구조 인식**: 추출된 텍스트 중에서 테이블 구조를 인식합니다. 일부 OCR 엔진은 테이블 구조를 자동으로 인식하는 기능을 제공하지만, 그렇지 않은 경우에는 텍스트의 위치 정보를 사용하여 수동으로 테이블 구조를 재구성해야 할 수 있습니다.\n",
            "\n",
            "5. **데이터 정제 및 변환**: 테이블 구조를 인식한 후, 필요에 따라 데이터를 정제하고 원하는 형식으로 변환합니다. 예를 들어, 불필요한 공백을 제거하거나, 특정 열의 데이터를 숫자 형태로 변환하는 등의 작업을 수행할 수 있습니다.\n",
            "\n",
            "6. **데이터 저장**: 파싱된 테이블 데이터를 데이터베이스, CSV 파일, JSON 파일 등 원하는 형식으로 저장합니다.\n",
            "\n",
            "OCR을 사용한 테이블 파싱은 복잡한 테이블 구조나 낮은 이미지 품질로 인해 어려움을 겪을 수 있습니다. 따라서, 고급 OCR 기술이나 추가적인 이미지 전처리 기술을 적용하여 정확도를 높일 수 있습니다.\n",
            "\n",
            "실제 구현에 있어서는 사용하고자 하는 OCR 엔진의 문서와 예제 코드를 참고하는 것이 도움이 됩니다.\n"
          ]
        }
      ],
      "source": [
        "# 동일한 세션아이디로 테스트\n",
        "response = agent_with_chat_history.invoke(\n",
        "    {\n",
        "        \"input\": \"OCR 테이블 파싱하는 방법을 알려주세요\"\n",
        "    },\n",
        "    config={\"configurable\": {\"session_id\": \"MyTestSessionID\"}},\n",
        ")\n",
        "print(f\"답변: {response['output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jDhqH0zWii31",
      "metadata": {
        "id": "jDhqH0zWii31"
      },
      "source": [
        "### **Agent Template Full Code** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "id": "xes7L2BbimXR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xes7L2BbimXR",
        "outputId": "a036198c-0b08-4e09-9c35-5f75e2f49431"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mOCR (Optical Character Recognition)을 사용하여 테이블을 파싱하는 과정은 이미지나 PDF 내의 텍스트를 추출하고, 이를 구조화된 형태로 변환하는 작업을 포함합니다. 테이블 파싱은 특히 데이터를 정확하게 추출하고 구조화하는 것이 중요한 작업입니다. 다음은 OCR을 사용하여 테이블을 파싱하는 기본적인 단계입니다:\n",
            "\n",
            "1. **이미지 준비**: 파싱할 테이블이 포함된 문서나 이미지를 준비합니다. 이미지의 품질이 좋을수록 OCR의 정확도가 높아집니다.\n",
            "\n",
            "2. **OCR 엔진 선택**: Tesseract, Google Vision API, Amazon Textract 등 다양한 OCR 엔진 중에서 선택할 수 있습니다. 각 엔진마다 특성과 성능이 다르므로, 요구사항에 맞는 엔진을 선택하는 것이 중요합니다.\n",
            "\n",
            "3. **텍스트 추출**: 선택한 OCR 엔진을 사용하여 이미지에서 텍스트를 추출합니다. 이 과정에서 엔진은 이미지 내의 문자를 인식하고, 이를 디지털 텍스트로 변환합니다.\n",
            "\n",
            "4. **테이블 구조 인식**: 추출된 텍스트만으로는 테이블의 구조를 알 수 없기 때문에, 테이블의 행과 열을 인식하는 추가적인 처리가 필요합니다. 일부 OCR 엔진은 테이블 구조를 자동으로 인식하는 기능을 제공하기도 합니다.\n",
            "\n",
            "5. **데이터 정제 및 변환**: 테이블 구조를 인식한 후, 데이터를 필요한 형태로 정제하고 변환합니다. 예를 들어, 특정 열만 추출하거나, 데이터를 CSV, JSON 등의 형식으로 변환할 수 있습니다.\n",
            "\n",
            "6. **검증 및 수정**: OCR과 테이블 파싱 과정에서 오류가 발생할 수 있으므로, 결과 데이터를 검증하고 필요한 경우 수동으로 수정합니다.\n",
            "\n",
            "### 예시: Tesseract를 사용한 테이블 파싱\n",
            "\n",
            "Tesseract OCR은 오픈 소스 OCR 엔진으로, 테이블 파싱에도 사용할 수 있습니다. 다음은 Tesseract를 사용하여 테이블을 파싱하는 간단한 예시입니다:\n",
            "\n",
            "1. Tesseract 설치: Tesseract OCR을 시스템에 설치합니다.\n",
            "\n",
            "2. 이미지 준비: 파싱할 테이블이 포함된 이미지를 준비합니다.\n",
            "\n",
            "3. Tesseract 실행: 터미널이나 명령 프롬프트에서 다음 명령어를 실행하여 이미지에서 텍스트를 추출합니다.\n",
            "   ```\n",
            "   tesseract 이미지파일명 출력파일명\n",
            "   ```\n",
            "   이 명령어는 `이미지파일명`에서 텍스트를 추출하여 `출력파일명.txt`에 저장합니다.\n",
            "\n",
            "4. 테이블 구조 인식 및 데이터 변환: 추출된 텍스트를 분석하여 테이블 구조를 인식하고, 필요한 형식으로 데이터를 변환합니다. 이 단계는 추가적인 스크립트나 소프트웨어가 필요할 수 있습니다.\n",
            "\n",
            "OCR을 사용한 테이블 파싱은 복잡한 과정일 수 있으며, 특히 테이블 구조 인식과 데이터 변환 단계에서는 맞춤형 처리가 필요할 수 있습니다. 따라서, 프로젝트의 요구사항과 사용 가능한 리소스를 고려하여 적절한 도구와 접근 방식을 선택하는 것이 중요합니다.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "답변: OCR (Optical Character Recognition)을 사용하여 테이블을 파싱하는 과정은 이미지나 PDF 내의 텍스트를 추출하고, 이를 구조화된 형태로 변환하는 작업을 포함합니다. 테이블 파싱은 특히 데이터를 정확하게 추출하고 구조화하는 것이 중요한 작업입니다. 다음은 OCR을 사용하여 테이블을 파싱하는 기본적인 단계입니다:\n",
            "\n",
            "1. **이미지 준비**: 파싱할 테이블이 포함된 문서나 이미지를 준비합니다. 이미지의 품질이 좋을수록 OCR의 정확도가 높아집니다.\n",
            "\n",
            "2. **OCR 엔진 선택**: Tesseract, Google Vision API, Amazon Textract 등 다양한 OCR 엔진 중에서 선택할 수 있습니다. 각 엔진마다 특성과 성능이 다르므로, 요구사항에 맞는 엔진을 선택하는 것이 중요합니다.\n",
            "\n",
            "3. **텍스트 추출**: 선택한 OCR 엔진을 사용하여 이미지에서 텍스트를 추출합니다. 이 과정에서 엔진은 이미지 내의 문자를 인식하고, 이를 디지털 텍스트로 변환합니다.\n",
            "\n",
            "4. **테이블 구조 인식**: 추출된 텍스트만으로는 테이블의 구조를 알 수 없기 때문에, 테이블의 행과 열을 인식하는 추가적인 처리가 필요합니다. 일부 OCR 엔진은 테이블 구조를 자동으로 인식하는 기능을 제공하기도 합니다.\n",
            "\n",
            "5. **데이터 정제 및 변환**: 테이블 구조를 인식한 후, 데이터를 필요한 형태로 정제하고 변환합니다. 예를 들어, 특정 열만 추출하거나, 데이터를 CSV, JSON 등의 형식으로 변환할 수 있습니다.\n",
            "\n",
            "6. **검증 및 수정**: OCR과 테이블 파싱 과정에서 오류가 발생할 수 있으므로, 결과 데이터를 검증하고 필요한 경우 수동으로 수정합니다.\n",
            "\n",
            "### 예시: Tesseract를 사용한 테이블 파싱\n",
            "\n",
            "Tesseract OCR은 오픈 소스 OCR 엔진으로, 테이블 파싱에도 사용할 수 있습니다. 다음은 Tesseract를 사용하여 테이블을 파싱하는 간단한 예시입니다:\n",
            "\n",
            "1. Tesseract 설치: Tesseract OCR을 시스템에 설치합니다.\n",
            "\n",
            "2. 이미지 준비: 파싱할 테이블이 포함된 이미지를 준비합니다.\n",
            "\n",
            "3. Tesseract 실행: 터미널이나 명령 프롬프트에서 다음 명령어를 실행하여 이미지에서 텍스트를 추출합니다.\n",
            "   ```\n",
            "   tesseract 이미지파일명 출력파일명\n",
            "   ```\n",
            "   이 명령어는 `이미지파일명`에서 텍스트를 추출하여 `출력파일명.txt`에 저장합니다.\n",
            "\n",
            "4. 테이블 구조 인식 및 데이터 변환: 추출된 텍스트를 분석하여 테이블 구조를 인식하고, 필요한 형식으로 데이터를 변환합니다. 이 단계는 추가적인 스크립트나 소프트웨어가 필요할 수 있습니다.\n",
            "\n",
            "OCR을 사용한 테이블 파싱은 복잡한 과정일 수 있으며, 특히 테이블 구조 인식과 데이터 변환 단계에서는 맞춤형 처리가 필요할 수 있습니다. 따라서, 프로젝트의 요구사항과 사용 가능한 리소스를 고려하여 적절한 도구와 접근 방식을 선택하는 것이 중요합니다.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "########## 1. 도구를 정의합니다 ##########\n",
        "\n",
        "### 1-1. Search 도구 ###\n",
        "# TavilySearchResults 클래스의 인스턴스를 생성합니다\n",
        "# k=5은 검색 결과를 5개까지 가져오겠다는 의미입니다\n",
        "search = TavilySearchResults(k=5)\n",
        "\n",
        "### 1-2. PDF 문서 검색 도구 (Retriever) ###\n",
        "# PDF 파일 로드. 파일의 경로 입력\n",
        "loader = PyPDFLoader(\"/content/layout-parser-readthedocs-io-en-latest.pdf\")\n",
        "\n",
        "# 텍스트 분할기를 사용하여 문서를 분할합니다.\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "# 문서를 로드하고 분할합니다.\n",
        "split_docs = loader.load_and_split(text_splitter)\n",
        "\n",
        "# VectorStore를 생성합니다.\n",
        "vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
        "\n",
        "# Retriever를 생성합니다.\n",
        "retriever = vector.as_retriever()\n",
        "\n",
        "# langchain 패키지의 tools 모듈에서 retriever 도구를 생성\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    name=\"pdf_search\",\n",
        "    # 도구에 대한 설명을 자세히 기입해야 합니다!!!\n",
        "    description=\"PDF와 관련된 질문은 이 도구를 사용해야 합니다!\",\n",
        ")\n",
        "\n",
        "### 1-3. tools 리스트에 도구 목록을 추가합니다 ###\n",
        "# tools 리스트에 search와 retriever_tool을 추가합니다.\n",
        "tools = [search, retriever_tool]\n",
        "\n",
        "########## 2. LLM 을 정의합니다 ##########\n",
        "# LLM 모델을 생성합니다.\n",
        "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0)\n",
        "\n",
        "########## 3. Prompt 를 정의합니다 ##########\n",
        "\n",
        "# hub에서 prompt를 가져옵니다 - 이 부분을 수정할 수 있습니다!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "########## 4. Agent 를 정의합니다 ##########\n",
        "\n",
        "# OpenAI 함수 기반 에이전트를 생성합니다.\n",
        "# llm, tools, prompt를 인자로 사용합니다.\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "\n",
        "########## 5. AgentExecutor 를 정의합니다 ##########\n",
        "\n",
        "# AgentExecutor 클래스를 사용하여 agent와 tools를 설정하고, 상세한 로그를 출력하도록 verbose를 True로 설정합니다.\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "########## 6. 채팅 기록을 수행하는 메모리를 추가합니다. ##########\n",
        "\n",
        "# 채팅 메시지 기록을 관리하는 객체를 생성합니다.\n",
        "message_history = ChatMessageHistory()\n",
        "\n",
        "# 채팅 메시지 기록이 추가된 에이전트를 생성합니다.\n",
        "agent_with_chat_history = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    # 대부분의 실제 시나리오에서 세션 ID가 필요하기 때문에 이것이 필요합니다\n",
        "    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n",
        "    lambda session_id: message_history,\n",
        "    # 프롬프트의 질문이 입력되는 key: \"input\"\n",
        "    input_messages_key=\"input\",\n",
        "    # 프롬프트의 메시지가 입력되는 key: \"chat_history\"\n",
        "    history_messages_key=\"chat_history\",\n",
        ")\n",
        "\n",
        "########## 7. 질의-응답 테스트를 수행합니다. ##########\n",
        "\n",
        "# 질의에 대한 답변을 출력합니다.\n",
        "response = agent_with_chat_history.invoke(\n",
        "    {\n",
        "        \"input\": \"OCR 테이블 파싱하는 방법을 알려주세요\"\n",
        "    },\n",
        "    # 세션 ID를 설정합니다.\n",
        "    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n",
        "    config={\"configurable\": {\"session_id\": \"MyTestSessionID\"}},\n",
        ")\n",
        "print(f\"답변: {response['output']}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
