{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9fa23b62",
      "metadata": {
        "id": "9fa23b62"
      },
      "source": [
        "# OpenAI Function Calling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da7d9df3",
      "metadata": {},
      "source": [
        "#### 필수 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "354b1e04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "354b1e04",
        "outputId": "c07cb9a3-de07-40f0-ea9a-a70da79a3f8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain-openai langchain_community langchain_experimental langchain-text-splitters tiktoken pypdf faiss-cpu wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7368b9c9",
      "metadata": {},
      "source": [
        "#### OpenAI API 설정 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8U_lhAypNH9G",
      "metadata": {
        "id": "8U_lhAypNH9G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-*****************************************************'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-cDLpads8gGD",
      "metadata": {
        "id": "-cDLpads8gGD"
      },
      "outputs": [],
      "source": [
        "#JSON 타입의 결과를 반환하는 함수를 생성\n",
        "#OPEN AI Function으로 사용하기 위해 주석으로 함수에 대한 설명을 부여함\n",
        "\n",
        "import json\n",
        "\n",
        "# Example dummy function hard coded to return the same weather\n",
        "# In production, this could be your backend API or an external API\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "    weather_info = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": \"72\",\n",
        "        \"unit\": unit,\n",
        "        \"forecast\": [\"sunny\", \"windy\"],\n",
        "    }\n",
        "    return json.dumps(weather_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcXVSXzX8j9i",
      "metadata": {
        "id": "bcXVSXzX8j9i"
      },
      "outputs": [],
      "source": [
        "# define a function\n",
        "functions = [\n",
        "    {\n",
        "      \"name\": \"weather_search\",\n",
        "      \"description\": \"Search for weather given an airport code\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"airport_code\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The airport code to get the weather for\"\n",
        "          },\n",
        "        },\n",
        "        \"required\": [\"airport_code\"]\n",
        "      }\n",
        "    },\n",
        "        {\n",
        "      \"name\": \"sports_search\",\n",
        "      \"description\": \"Search for news of recent sport events\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"team_name\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The sports team to search for\"\n",
        "          },\n",
        "        },\n",
        "        \"required\": [\"team_name\"]\n",
        "      }\n",
        "    }\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PnYDGVb-8soq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnYDGVb-8soq",
        "outputId": "21d58fd9-07e8-4532-ea68-030e8e47e3ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "#프롬프트 생성\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "#모델 생성\n",
        "model = ChatOpenAI(temperature=0).bind(functions=functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SEKh30_J80DS",
      "metadata": {
        "id": "SEKh30_J80DS"
      },
      "outputs": [],
      "source": [
        "#runnable 생성\n",
        "runnable = prompt | model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1MIF6Lq99wJm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MIF6Lq99wJm",
        "outputId": "5f2a771b-d043-489b-d9c2-59f0706abe72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'weather_search'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#runnable 테스트\n",
        "runnable.invoke({\"input\": \"what is the weather in sf\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X3f5KDIE-N2A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3f5KDIE-N2A",
        "outputId": "9a1659ad-3729-44f2-c967-cfcbcfb59efd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"team_name\":\"한화이글스\"}', 'name': 'sports_search'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#자동으로 runnable이 문장에서 required 변수값을 찾아 지정하는 것을 확인할 수 있음.\n",
        "runnable.invoke({\"input\": \"한화이글스에 대한 최신뉴스\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4oIZVrPI_n2n",
      "metadata": {
        "id": "4oIZVrPI_n2n"
      },
      "source": [
        "**Pydantic to OpenAI function definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sIgmdTiR_5MW",
      "metadata": {
        "id": "sIgmdTiR_5MW"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZNmvVBhM_pE3",
      "metadata": {
        "id": "ZNmvVBhM_pE3"
      },
      "outputs": [],
      "source": [
        "# Output Value 생성\n",
        "class WeatherSearch(BaseModel):\n",
        "    \"\"\"Call this with an airport code to get the weather at that airport\"\"\"\n",
        "    airport_code: str = Field(description=\"airport code to get weather for\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_PpqtfdJAkWX",
      "metadata": {
        "id": "_PpqtfdJAkWX"
      },
      "outputs": [],
      "source": [
        "class ArtistSearch(BaseModel):\n",
        "    \"\"\"Call this to get the names of songs by a particular artist\"\"\"\n",
        "    artist_name: str = Field(description=\"name of artist to look up\")\n",
        "    n: int = Field(description=\"number of results\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t33-prPWA9ZH",
      "metadata": {
        "id": "t33-prPWA9ZH"
      },
      "outputs": [],
      "source": [
        "class SportsSearch(BaseModel):\n",
        "    \"\"\"Call this to search for news of recent sport events\"\"\"\n",
        "    team_name: str = Field(description=\"The sports team to search for\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "q5D0OHgk_7tu",
      "metadata": {
        "id": "q5D0OHgk_7tu"
      },
      "outputs": [],
      "source": [
        "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iPnvagr7__TQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPnvagr7__TQ",
        "outputId": "9252ca96-665c-4e42-8904-9bdebc4f4d5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.2.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "# Pydantic OutputValues를 openai function으로 변환 및 리스트화\n",
        "functions = [\n",
        "    convert_pydantic_to_openai_function(WeatherSearch),\n",
        "    convert_pydantic_to_openai_function(ArtistSearch),\n",
        "    convert_pydantic_to_openai_function(SportsSearch),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JgIdkZ1XAQYY",
      "metadata": {
        "id": "JgIdkZ1XAQYY"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "#모델 생성\n",
        "model = ChatOpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LrV6VU23Bbc_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrV6VU23Bbc_",
        "outputId": "3ad4bc19-f4ed-4cb4-c962-1d597096c6c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"artist_name\":\"김현정\",\"n\":5}', 'name': 'ArtistSearch'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#함수를 입력하여 모델 테스트\n",
        "#아티스트 검색 함수 실행 테스트\n",
        "model.invoke(\"한국 가수 김현정의 히트곡은?\", functions=functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DY5G2Y-JBck9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY5G2Y-JBck9",
        "outputId": "0e6ec729-5509-4222-cdbe-a3e66556d758"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"team_name\":\"한화이글스\"}', 'name': 'SportsSearch'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#스포츠 검색 함수 실행 테스트\n",
        "model.invoke(\"한화이글스 최신뉴스?\", functions=functions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Qlnhs1U0CFIV",
      "metadata": {
        "id": "Qlnhs1U0CFIV"
      },
      "source": [
        "## Tools and Routing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RbWurLReCECz",
      "metadata": {
        "id": "RbWurLReCECz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#key 등록\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"tvly-*********************************************\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"default\"\n",
        "\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "search = TavilySearchResults(k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NlW7FIJECKDF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlW7FIJECKDF",
        "outputId": "a43060c0-3012-4f89-8c3a-bef66cbd38e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('tavily_search_results_json',\n",
              " 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.',\n",
              " {'query': {'title': 'Query',\n",
              "   'description': 'search query to look up',\n",
              "   'type': 'string'}})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search.name,search.description,search.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bM9teXZDau9",
      "metadata": {
        "id": "7bM9teXZDau9"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from pydantic import BaseModel, Field\n",
        "import datetime\n",
        "from langchain.agents import tool\n",
        "\n",
        "#함수를 툴로 변환\n",
        "#Pydantic을 사용하여 Input값으로 latitude 와 longtude를 착륙시킴\n",
        "@tool\n",
        "def get_current_temperature(latitude:float, longitude: float) -> dict:\n",
        "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
        "\n",
        "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "    # Parameters for the request\n",
        "    params = {\n",
        "        'latitude': latitude,\n",
        "        'longitude': longitude,\n",
        "        'hourly': 'temperature_2m',\n",
        "        'forecast_days': 1,\n",
        "    }\n",
        "\n",
        "    # Make the request\n",
        "    response = requests.get(BASE_URL, params=params)\n",
        "\n",
        "    #응답 결과를 json타입으로 전달받음\n",
        "    if response.status_code == 200:\n",
        "        results = response.json()\n",
        "    else:\n",
        "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
        "\n",
        "    current_utc_time = datetime.datetime.utcnow()\n",
        "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
        "    temperature_list = results['hourly']['temperature_2m']\n",
        "\n",
        "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
        "    current_temperature = temperature_list[closest_time_index]\n",
        "\n",
        "    return f'The current temperature is {current_temperature}°C'\n",
        "\n",
        "import wikipedia\n",
        "\n",
        "@tool\n",
        "def search_wikipedia(query: str) -> str:\n",
        "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
        "    page_titles = wikipedia.search(query)\n",
        "    summaries = []\n",
        "\n",
        "    #wiki page content summary \n",
        "    for page_title in page_titles[: 3]:\n",
        "        try:\n",
        "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
        "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
        "        except (\n",
        "            self.wiki_client.exceptions.PageError,\n",
        "            self.wiki_client.exceptions.DisambiguationError,\n",
        "        ):\n",
        "            pass\n",
        "    if not summaries:\n",
        "        return \"No good Wikipedia Search Result was found\"\n",
        "    return \"\\n\\n\".join(summaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6yu2jgXFFbGI",
      "metadata": {
        "id": "6yu2jgXFFbGI"
      },
      "outputs": [],
      "source": [
        "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sJH6K8DYFbGI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJH6K8DYFbGI",
        "outputId": "d16b014b-c6e0-460b-97ef-94aa680ef1e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.2.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
        "from langchain.utilities.openapi import OpenAPISpec\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "\n",
        "#openai function으로 변경\n",
        "functions = [\n",
        "    format_tool_to_openai_function(f) for f in [\n",
        "        search, search_wikipedia, get_current_temperature\n",
        "    ]\n",
        "]\n",
        "\n",
        "#모델에 함수 적용\n",
        "model = ChatOpenAI(temperature=0).bind(functions=functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RnAuDgkbF9qi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RnAuDgkbF9qi",
        "outputId": "363fc035-6914-4e70-f165-d4ced4443ee0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The current temperature is 26.4°C'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#날짜 함수 테스트\n",
        "get_current_temperature({\"latitude\": 13, \"longitude\": 14})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9BfomBsmGHhA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "9BfomBsmGHhA",
        "outputId": "4fc263ab-2852-4699-a9be-efa79c70be75"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: OpenAI\\nSummary: OpenAI is a U.S. based artificial intelligence (AI) research organization founded in December 2015, researching artificial intelligence with the goal of developing \"safe and beneficial\" artificial general intelligence, which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\".\\nAs one of the leading organizations of the AI spring, it has developed several large language models, advanced image generation models, and previously, released open-source models. Its release of ChatGPT has been credited with starting the AI spring.The organization consists of the non-profit OpenAI, Inc. registered in Delaware and its for-profit subsidiary OpenAI Global, LLC. It was founded by Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, Jessica Livingston, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk serving as the initial Board of Directors members. Microsoft provided OpenAI Global LLC with a $1 billion investment in 2019 and a $10 billion investment in 2023, with a significant portion of the investment in the form of computational resources on Microsoft\\'s Azure cloud service.On November 17, 2023, the board removed Altman as CEO, while Brockman was removed as chairman and then resigned as president. Four days later, both returned after negotiations with the board, and most of the board members resigned. The new initial board included former Salesforce co-CEO Bret Taylor as chairman. It was also announced that Microsoft will have a non-voting board seat.\\n\\nPage: DataStax\\nSummary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#wiki 함수 테스트\n",
        "search_wikipedia({\"query\": \"langchain\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xRPRsQSE-ZUu",
      "metadata": {
        "id": "xRPRsQSE-ZUu"
      },
      "source": [
        "**OPENAPI to Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4vIvpA5v6ipK",
      "metadata": {
        "id": "4vIvpA5v6ipK"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
        "from langchain.utilities.openapi import OpenAPISpec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KIcuDI5e6lpp",
      "metadata": {
        "id": "KIcuDI5e6lpp"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "{\n",
        "  \"openapi\": \"3.0.0\",\n",
        "  \"info\": {\n",
        "    \"version\": \"1.0.0\",\n",
        "    \"title\": \"Swagger Petstore\",\n",
        "    \"license\": {\n",
        "      \"name\": \"MIT\"\n",
        "    }\n",
        "  },\n",
        "  \"servers\": [\n",
        "    {\n",
        "      \"url\": \"http://petstore.swagger.io/v1\"\n",
        "    }\n",
        "  ],\n",
        "  \"paths\": {\n",
        "    \"/pets\": {\n",
        "      \"get\": {\n",
        "        \"summary\": \"List all pets\",\n",
        "        \"operationId\": \"listPets\",\n",
        "        \"tags\": [\n",
        "          \"pets\"\n",
        "        ],\n",
        "        \"parameters\": [\n",
        "          {\n",
        "            \"name\": \"limit\",\n",
        "            \"in\": \"query\",\n",
        "            \"description\": \"How many items to return at one time (max 100)\",\n",
        "            \"required\": false,\n",
        "            \"schema\": {\n",
        "              \"type\": \"integer\",\n",
        "              \"maximum\": 100,\n",
        "              \"format\": \"int32\"\n",
        "            }\n",
        "          }\n",
        "        ],\n",
        "        \"responses\": {\n",
        "          \"200\": {\n",
        "            \"description\": \"A paged array of pets\",\n",
        "            \"headers\": {\n",
        "              \"x-next\": {\n",
        "                \"description\": \"A link to the next page of responses\",\n",
        "                \"schema\": {\n",
        "                  \"type\": \"string\"\n",
        "                }\n",
        "              }\n",
        "            },\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Pets\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          },\n",
        "          \"default\": {\n",
        "            \"description\": \"unexpected error\",\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Error\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"post\": {\n",
        "        \"summary\": \"Create a pet\",\n",
        "        \"operationId\": \"createPets\",\n",
        "        \"tags\": [\n",
        "          \"pets\"\n",
        "        ],\n",
        "        \"responses\": {\n",
        "          \"201\": {\n",
        "            \"description\": \"Null response\"\n",
        "          },\n",
        "          \"default\": {\n",
        "            \"description\": \"unexpected error\",\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Error\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"/pets/{petId}\": {\n",
        "      \"get\": {\n",
        "        \"summary\": \"Info for a specific pet\",\n",
        "        \"operationId\": \"showPetById\",\n",
        "        \"tags\": [\n",
        "          \"pets\"\n",
        "        ],\n",
        "        \"parameters\": [\n",
        "          {\n",
        "            \"name\": \"petId\",\n",
        "            \"in\": \"path\",\n",
        "            \"required\": true,\n",
        "            \"description\": \"The id of the pet to retrieve\",\n",
        "            \"schema\": {\n",
        "              \"type\": \"string\"\n",
        "            }\n",
        "          }\n",
        "        ],\n",
        "        \"responses\": {\n",
        "          \"200\": {\n",
        "            \"description\": \"Expected response to a valid request\",\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Pet\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          },\n",
        "          \"default\": {\n",
        "            \"description\": \"unexpected error\",\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Error\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  },\n",
        "  \"components\": {\n",
        "    \"schemas\": {\n",
        "      \"Pet\": {\n",
        "        \"type\": \"object\",\n",
        "        \"required\": [\n",
        "          \"id\",\n",
        "          \"name\"\n",
        "        ],\n",
        "        \"properties\": {\n",
        "          \"id\": {\n",
        "            \"type\": \"integer\",\n",
        "            \"format\": \"int64\"\n",
        "          },\n",
        "          \"name\": {\n",
        "            \"type\": \"string\"\n",
        "          },\n",
        "          \"tag\": {\n",
        "            \"type\": \"string\"\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"Pets\": {\n",
        "        \"type\": \"array\",\n",
        "        \"maxItems\": 100,\n",
        "        \"items\": {\n",
        "          \"$ref\": \"#/components/schemas/Pet\"\n",
        "        }\n",
        "      },\n",
        "      \"Error\": {\n",
        "        \"type\": \"object\",\n",
        "        \"required\": [\n",
        "          \"code\",\n",
        "          \"message\"\n",
        "        ],\n",
        "        \"properties\": {\n",
        "          \"code\": {\n",
        "            \"type\": \"integer\",\n",
        "            \"format\": \"int32\"\n",
        "          },\n",
        "          \"message\": {\n",
        "            \"type\": \"string\"\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S0BmY0Rl817H",
      "metadata": {
        "id": "S0BmY0Rl817H"
      },
      "outputs": [],
      "source": [
        "#openapi 에 업로드 및 함수 확인\n",
        "spec = OpenAPISpec.from_text(text)\n",
        "pet_openai_functions, pet_callables = openapi_spec_to_openai_fn(spec)\n",
        "pet_openai_functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xvgZ9XVI8-22",
      "metadata": {
        "id": "xvgZ9XVI8-22"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "#모델에 함수 적용\n",
        "model = ChatOpenAI(temperature=0).bind(functions=pet_openai_functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SxGsitru9C7-",
      "metadata": {
        "id": "SxGsitru9C7-"
      },
      "outputs": [],
      "source": [
        "#모델 테스트\n",
        "model.invoke(\"what are three pets names\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qxYHS6ZW9Kqz",
      "metadata": {
        "id": "qxYHS6ZW9Kqz"
      },
      "outputs": [],
      "source": [
        "model.invoke(\"tell me about pet with id 42\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uOjjKxYV9OOq",
      "metadata": {
        "id": "uOjjKxYV9OOq"
      },
      "source": [
        "### **Routing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fA6-57o29Ptu",
      "metadata": {
        "id": "fA6-57o29Ptu"
      },
      "outputs": [],
      "source": [
        "#open ai function으로 함수 변형\n",
        "functions = [\n",
        "    format_tool_to_openai_function(f) for f in [\n",
        "        search_wikipedia, get_current_temperature\n",
        "    ]\n",
        "]\n",
        "\n",
        "#모델에 적용\n",
        "model = ChatOpenAI(temperature=0).bind(functions=functions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cKiHQVG59U0y",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKiHQVG59U0y",
        "outputId": "529d25b4-e173-4e06-a564-de9b7f4da6cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#모델 테스트\n",
        "model.invoke(\"what is the weather in sf right now\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W-PjbkDq9bD1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-PjbkDq9bD1",
        "outputId": "3648af1e-5b63-41c2-97f7-4b6dccc2d502"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"Langchain\"}', 'name': 'search_wikipedia'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.invoke(\"what is langchain\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TC9R37uk9exn",
      "metadata": {
        "id": "TC9R37uk9exn"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "#프롬프트 생성\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are helpful but sassy assistant\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "])\n",
        "\n",
        "#체인 생성\n",
        "chain = prompt | model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YNKNOga29g5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNKNOga29g5e",
        "outputId": "3b848635-7681-4792-e86a-a8aba3b484f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#체인 테스트\n",
        "chain.invoke({\"input\": \"what is the weather in sf right now\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bgoTO9xI9lTs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgoTO9xI9lTs",
        "outputId": "4bc799c9-fb65-47c1-c274-29b5cbcea1e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"Langchain\"}', 'name': 'search_wikipedia'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"what is langchain\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VzEGKt4L9sEL",
      "metadata": {
        "id": "VzEGKt4L9sEL"
      },
      "outputs": [],
      "source": [
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B-BATPeG9uvq",
      "metadata": {
        "id": "B-BATPeG9uvq"
      },
      "outputs": [],
      "source": [
        "#output parser 장착\n",
        "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eXWrw5hr9wxZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXWrw5hr9wxZ",
        "outputId": "19c2723f-ad53-4e2e-8df3-376673c29d29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AgentActionMessageLog(tool='get_current_temperature', tool_input={'latitude': 37.7749, 'longitude': -122.4194}, log=\"\\nInvoking: `get_current_temperature` with `{'latitude': 37.7749, 'longitude': -122.4194}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#테스트 및 비교\n",
        "chain.invoke({\"input\": \"what is the weather in sf right now\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a33Hx0P8-Bqg",
      "metadata": {
        "id": "a33Hx0P8-Bqg"
      },
      "outputs": [],
      "source": [
        "from langchain.schema.agent import AgentFinish\n",
        "\n",
        "#agnet 마무리 루트 설정\n",
        "def route(result):\n",
        "    #결과 값이 있으면 output 출력 / 아니면 tool 실행\n",
        "    if isinstance(result, AgentFinish):\n",
        "        return result.return_values['output']\n",
        "    else:\n",
        "        tools = {\n",
        "            \"search_wikipedia\": search_wikipedia,\n",
        "            \"get_current_temperature\": get_current_temperature,\n",
        "        }\n",
        "        return tools[result.tool].run(result.tool_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j0YHY445-EXW",
      "metadata": {
        "id": "j0YHY445-EXW"
      },
      "outputs": [],
      "source": [
        "#루트 장착\n",
        "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | route"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VF3Em9wB-G_C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VF3Em9wB-G_C",
        "outputId": "27b9af61-9ecf-4867-ce20-ea060123b956"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The current temperature is 9.6°C'"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#테스트\n",
        "chain.invoke({\"input\": \"What is the weather in san francisco right now?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1r0Wfnto-Il8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "1r0Wfnto-Il8",
        "outputId": "47b71d23-46b2-4d0d-a2f4-3906b4e12b5a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: OpenAI\\nSummary: OpenAI is a U.S. based artificial intelligence (AI) research organization founded in December 2015, researching artificial intelligence with the goal of developing \"safe and beneficial\" artificial general intelligence, which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\".\\nAs one of the leading organizations of the AI spring, it has developed several large language models, advanced image generation models, and previously, released open-source models. Its release of ChatGPT has been credited with starting the AI spring.The organization consists of the non-profit OpenAI, Inc. registered in Delaware and its for-profit subsidiary OpenAI Global, LLC. It was founded by Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, Jessica Livingston, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk serving as the initial Board of Directors members. Microsoft provided OpenAI Global LLC with a $1 billion investment in 2019 and a $10 billion investment in 2023, with a significant portion of the investment in the form of computational resources on Microsoft\\'s Azure cloud service.On November 17, 2023, the board removed Altman as CEO, while Brockman was removed as chairman and then resigned as president. Four days later, both returned after negotiations with the board, and most of the board members resigned. The new initial board included former Salesforce co-CEO Bret Taylor as chairman. It was also announced that Microsoft will have a non-voting board seat.\\n\\nPage: DataStax\\nSummary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"What is langchain?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Ol7DzUh-Ung",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1Ol7DzUh-Ung",
        "outputId": "e3fca2bf-7c10-48d4-b17a-3c9c8a7cd85c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Well, hello there! How can I assist you today?'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"hi!\"})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
