{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9fa23b62",
      "metadata": {
        "id": "9fa23b62"
      },
      "source": [
        "# OpenAI Function Calling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "354b1e04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "354b1e04",
        "outputId": "c07cb9a3-de07-40f0-ea9a-a70da79a3f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain-openai langchain_community langchain_experimental langchain-text-splitters tiktoken pypdf faiss-cpu wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = 'sk-*****************************************************'"
      ],
      "metadata": {
        "id": "8U_lhAypNH9G"
      },
      "id": "8U_lhAypNH9G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Example dummy function hard coded to return the same weather\n",
        "# In production, this could be your backend API or an external API\n",
        "def get_current_weather(location, unit=\"fahrenheit\"):\n",
        "    \"\"\"Get the current weather in a given location\"\"\"\n",
        "    weather_info = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": \"72\",\n",
        "        \"unit\": unit,\n",
        "        \"forecast\": [\"sunny\", \"windy\"],\n",
        "    }\n",
        "    return json.dumps(weather_info)"
      ],
      "metadata": {
        "id": "-cDLpads8gGD"
      },
      "id": "-cDLpads8gGD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function\n",
        "functions = [\n",
        "    {\n",
        "      \"name\": \"weather_search\",\n",
        "      \"description\": \"Search for weather given an airport code\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"airport_code\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The airport code to get the weather for\"\n",
        "          },\n",
        "        },\n",
        "        \"required\": [\"airport_code\"]\n",
        "      }\n",
        "    },\n",
        "        {\n",
        "      \"name\": \"sports_search\",\n",
        "      \"description\": \"Search for news of recent sport events\",\n",
        "      \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "          \"team_name\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The sports team to search for\"\n",
        "          },\n",
        "        },\n",
        "        \"required\": [\"team_name\"]\n",
        "      }\n",
        "    }\n",
        "  ]"
      ],
      "metadata": {
        "id": "bcXVSXzX8j9i"
      },
      "id": "bcXVSXzX8j9i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\")\n",
        "    ]\n",
        ")\n",
        "model = ChatOpenAI(temperature=0).bind(functions=functions)"
      ],
      "metadata": {
        "id": "PnYDGVb-8soq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d58fd9-07e8-4532-ea68-030e8e47e3ac"
      },
      "id": "PnYDGVb-8soq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runnable = prompt | model"
      ],
      "metadata": {
        "id": "SEKh30_J80DS"
      },
      "id": "SEKh30_J80DS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runnable.invoke({\"input\": \"what is the weather in sf\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MIF6Lq99wJm",
        "outputId": "5f2a771b-d043-489b-d9c2-59f0706abe72"
      },
      "id": "1MIF6Lq99wJm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'weather_search'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runnable.invoke({\"input\": \"한화이글스에 대한 최신뉴스\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3f5KDIE-N2A",
        "outputId": "9a1659ad-3729-44f2-c967-cfcbcfb59efd"
      },
      "id": "X3f5KDIE-N2A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"team_name\":\"한화이글스\"}', 'name': 'sports_search'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pydantic to OpenAI function definition**"
      ],
      "metadata": {
        "id": "4oIZVrPI_n2n"
      },
      "id": "4oIZVrPI_n2n"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "sIgmdTiR_5MW"
      },
      "id": "sIgmdTiR_5MW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WeatherSearch(BaseModel):\n",
        "    \"\"\"Call this with an airport code to get the weather at that airport\"\"\"\n",
        "    airport_code: str = Field(description=\"airport code to get weather for\")"
      ],
      "metadata": {
        "id": "ZNmvVBhM_pE3"
      },
      "id": "ZNmvVBhM_pE3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ArtistSearch(BaseModel):\n",
        "    \"\"\"Call this to get the names of songs by a particular artist\"\"\"\n",
        "    artist_name: str = Field(description=\"name of artist to look up\")\n",
        "    n: int = Field(description=\"number of results\")"
      ],
      "metadata": {
        "id": "_PpqtfdJAkWX"
      },
      "id": "_PpqtfdJAkWX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SportsSearch(BaseModel):\n",
        "    \"\"\"Call this to search for news of recent sport events\"\"\"\n",
        "    team_name: str = Field(description=\"The sports team to search for\")"
      ],
      "metadata": {
        "id": "t33-prPWA9ZH"
      },
      "id": "t33-prPWA9ZH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
      ],
      "metadata": {
        "id": "q5D0OHgk_7tu"
      },
      "id": "q5D0OHgk_7tu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "functions = [\n",
        "    convert_pydantic_to_openai_function(WeatherSearch),\n",
        "    convert_pydantic_to_openai_function(ArtistSearch),\n",
        "    convert_pydantic_to_openai_function(SportsSearch),\n",
        "]"
      ],
      "metadata": {
        "id": "iPnvagr7__TQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9252ca96-665c-4e42-8904-9bdebc4f4d5a"
      },
      "id": "iPnvagr7__TQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.2.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI()"
      ],
      "metadata": {
        "id": "JgIdkZ1XAQYY"
      },
      "id": "JgIdkZ1XAQYY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(\"한국 가수 김현정의 히트곡은?\", functions=functions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrV6VU23Bbc_",
        "outputId": "3ad4bc19-f4ed-4cb4-c962-1d597096c6c1"
      },
      "id": "LrV6VU23Bbc_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"artist_name\":\"김현정\",\"n\":5}', 'name': 'ArtistSearch'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(\"한화이글스 최신뉴스?\", functions=functions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY5G2Y-JBck9",
        "outputId": "0e6ec729-5509-4222-cdbe-a3e66556d758"
      },
      "id": "DY5G2Y-JBck9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"team_name\":\"한화이글스\"}', 'name': 'SportsSearch'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools and Routing"
      ],
      "metadata": {
        "id": "Qlnhs1U0CFIV"
      },
      "id": "Qlnhs1U0CFIV"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"tvly-*********************************************\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"default\"\n",
        "\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "search = TavilySearchResults(k=5)"
      ],
      "metadata": {
        "id": "RbWurLReCECz"
      },
      "id": "RbWurLReCECz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search.name,search.description,search.args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlW7FIJECKDF",
        "outputId": "a43060c0-3012-4f89-8c3a-bef66cbd38e8"
      },
      "id": "NlW7FIJECKDF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tavily_search_results_json',\n",
              " 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.',\n",
              " {'query': {'title': 'Query',\n",
              "   'description': 'search query to look up',\n",
              "   'type': 'string'}})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pydantic import BaseModel, Field\n",
        "import datetime\n",
        "from langchain.agents import tool\n",
        "\n",
        "@tool\n",
        "def get_current_temperature(latitude:float, longitude: float) -> dict:\n",
        "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
        "\n",
        "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "    # Parameters for the request\n",
        "    params = {\n",
        "        'latitude': latitude,\n",
        "        'longitude': longitude,\n",
        "        'hourly': 'temperature_2m',\n",
        "        'forecast_days': 1,\n",
        "    }\n",
        "\n",
        "    # Make the request\n",
        "    response = requests.get(BASE_URL, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        results = response.json()\n",
        "    else:\n",
        "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
        "\n",
        "    current_utc_time = datetime.datetime.utcnow()\n",
        "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
        "    temperature_list = results['hourly']['temperature_2m']\n",
        "\n",
        "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
        "    current_temperature = temperature_list[closest_time_index]\n",
        "\n",
        "    return f'The current temperature is {current_temperature}°C'\n",
        "\n",
        "import wikipedia\n",
        "\n",
        "@tool\n",
        "def search_wikipedia(query: str) -> str:\n",
        "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
        "    page_titles = wikipedia.search(query)\n",
        "    summaries = []\n",
        "    for page_title in page_titles[: 3]:\n",
        "        try:\n",
        "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
        "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
        "        except (\n",
        "            self.wiki_client.exceptions.PageError,\n",
        "            self.wiki_client.exceptions.DisambiguationError,\n",
        "        ):\n",
        "            pass\n",
        "    if not summaries:\n",
        "        return \"No good Wikipedia Search Result was found\"\n",
        "    return \"\\n\\n\".join(summaries)"
      ],
      "metadata": {
        "id": "7bM9teXZDau9"
      },
      "id": "7bM9teXZDau9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
      ],
      "metadata": {
        "id": "6yu2jgXFFbGI"
      },
      "execution_count": null,
      "outputs": [],
      "id": "6yu2jgXFFbGI"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
        "from langchain.utilities.openapi import OpenAPISpec\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "\n",
        "functions = [\n",
        "    format_tool_to_openai_function(f) for f in [\n",
        "        search, search_wikipedia, get_current_temperature\n",
        "    ]\n",
        "]\n",
        "model = ChatOpenAI(temperature=0).bind(functions=functions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJH6K8DYFbGI",
        "outputId": "d16b014b-c6e0-460b-97ef-94aa680ef1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.2.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "id": "sJH6K8DYFbGI"
    },
    {
      "cell_type": "code",
      "source": [
        "get_current_temperature({\"latitude\": 13, \"longitude\": 14})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RnAuDgkbF9qi",
        "outputId": "363fc035-6914-4e70-f165-d4ced4443ee0"
      },
      "id": "RnAuDgkbF9qi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current temperature is 26.4°C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_wikipedia({\"query\": \"langchain\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "9BfomBsmGHhA",
        "outputId": "4fc263ab-2852-4699-a9be-efa79c70be75"
      },
      "id": "9BfomBsmGHhA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: OpenAI\\nSummary: OpenAI is a U.S. based artificial intelligence (AI) research organization founded in December 2015, researching artificial intelligence with the goal of developing \"safe and beneficial\" artificial general intelligence, which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\".\\nAs one of the leading organizations of the AI spring, it has developed several large language models, advanced image generation models, and previously, released open-source models. Its release of ChatGPT has been credited with starting the AI spring.The organization consists of the non-profit OpenAI, Inc. registered in Delaware and its for-profit subsidiary OpenAI Global, LLC. It was founded by Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, Jessica Livingston, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk serving as the initial Board of Directors members. Microsoft provided OpenAI Global LLC with a $1 billion investment in 2019 and a $10 billion investment in 2023, with a significant portion of the investment in the form of computational resources on Microsoft\\'s Azure cloud service.On November 17, 2023, the board removed Altman as CEO, while Brockman was removed as chairman and then resigned as president. Four days later, both returned after negotiations with the board, and most of the board members resigned. The new initial board included former Salesforce co-CEO Bret Taylor as chairman. It was also announced that Microsoft will have a non-voting board seat.\\n\\nPage: DataStax\\nSummary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPENAPI to Function**"
      ],
      "metadata": {
        "id": "xRPRsQSE-ZUu"
      },
      "id": "xRPRsQSE-ZUu"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
        "from langchain.utilities.openapi import OpenAPISpec"
      ],
      "metadata": {
        "id": "4vIvpA5v6ipK"
      },
      "id": "4vIvpA5v6ipK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "{\n",
        "  \"openapi\": \"3.0.0\",\n",
        "  \"info\": {\n",
        "    \"version\": \"1.0.0\",\n",
        "    \"title\": \"Swagger Petstore\",\n",
        "    \"license\": {\n",
        "      \"name\": \"MIT\"\n",
        "    }\n",
        "  },\n",
        "  \"servers\": [\n",
        "    {\n",
        "      \"url\": \"http://petstore.swagger.io/v1\"\n",
        "    }\n",
        "  ],\n",
        "  \"paths\": {\n",
        "    \"/pets\": {\n",
        "      \"get\": {\n",
        "        \"summary\": \"List all pets\",\n",
        "        \"operationId\": \"listPets\",\n",
        "        \"tags\": [\n",
        "          \"pets\"\n",
        "        ],\n",
        "        \"parameters\": [\n",
        "          {\n",
        "            \"name\": \"limit\",\n",
        "            \"in\": \"query\",\n",
        "            \"description\": \"How many items to return at one time (max 100)\",\n",
        "            \"required\": false,\n",
        "            \"schema\": {\n",
        "              \"type\": \"integer\",\n",
        "              \"maximum\": 100,\n",
        "              \"format\": \"int32\"\n",
        "            }\n",
        "          }\n",
        "        ],\n",
        "        \"responses\": {\n",
        "          \"200\": {\n",
        "            \"description\": \"A paged array of pets\",\n",
        "            \"headers\": {\n",
        "              \"x-next\": {\n",
        "                \"description\": \"A link to the next page of responses\",\n",
        "                \"schema\": {\n",
        "                  \"type\": \"string\"\n",
        "                }\n",
        "              }\n",
        "            },\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Pets\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          },\n",
        "          \"default\": {\n",
        "            \"description\": \"unexpected error\",\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Error\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"post\": {\n",
        "        \"summary\": \"Create a pet\",\n",
        "        \"operationId\": \"createPets\",\n",
        "        \"tags\": [\n",
        "          \"pets\"\n",
        "        ],\n",
        "        \"responses\": {\n",
        "          \"201\": {\n",
        "            \"description\": \"Null response\"\n",
        "          },\n",
        "          \"default\": {\n",
        "            \"description\": \"unexpected error\",\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Error\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    },\n",
        "    \"/pets/{petId}\": {\n",
        "      \"get\": {\n",
        "        \"summary\": \"Info for a specific pet\",\n",
        "        \"operationId\": \"showPetById\",\n",
        "        \"tags\": [\n",
        "          \"pets\"\n",
        "        ],\n",
        "        \"parameters\": [\n",
        "          {\n",
        "            \"name\": \"petId\",\n",
        "            \"in\": \"path\",\n",
        "            \"required\": true,\n",
        "            \"description\": \"The id of the pet to retrieve\",\n",
        "            \"schema\": {\n",
        "              \"type\": \"string\"\n",
        "            }\n",
        "          }\n",
        "        ],\n",
        "        \"responses\": {\n",
        "          \"200\": {\n",
        "            \"description\": \"Expected response to a valid request\",\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Pet\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          },\n",
        "          \"default\": {\n",
        "            \"description\": \"unexpected error\",\n",
        "            \"content\": {\n",
        "              \"application/json\": {\n",
        "                \"schema\": {\n",
        "                  \"$ref\": \"#/components/schemas/Error\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  },\n",
        "  \"components\": {\n",
        "    \"schemas\": {\n",
        "      \"Pet\": {\n",
        "        \"type\": \"object\",\n",
        "        \"required\": [\n",
        "          \"id\",\n",
        "          \"name\"\n",
        "        ],\n",
        "        \"properties\": {\n",
        "          \"id\": {\n",
        "            \"type\": \"integer\",\n",
        "            \"format\": \"int64\"\n",
        "          },\n",
        "          \"name\": {\n",
        "            \"type\": \"string\"\n",
        "          },\n",
        "          \"tag\": {\n",
        "            \"type\": \"string\"\n",
        "          }\n",
        "        }\n",
        "      },\n",
        "      \"Pets\": {\n",
        "        \"type\": \"array\",\n",
        "        \"maxItems\": 100,\n",
        "        \"items\": {\n",
        "          \"$ref\": \"#/components/schemas/Pet\"\n",
        "        }\n",
        "      },\n",
        "      \"Error\": {\n",
        "        \"type\": \"object\",\n",
        "        \"required\": [\n",
        "          \"code\",\n",
        "          \"message\"\n",
        "        ],\n",
        "        \"properties\": {\n",
        "          \"code\": {\n",
        "            \"type\": \"integer\",\n",
        "            \"format\": \"int32\"\n",
        "          },\n",
        "          \"message\": {\n",
        "            \"type\": \"string\"\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KIcuDI5e6lpp"
      },
      "id": "KIcuDI5e6lpp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spec = OpenAPISpec.from_text(text)\n",
        "pet_openai_functions, pet_callables = openapi_spec_to_openai_fn(spec)\n",
        "pet_openai_functions"
      ],
      "metadata": {
        "id": "S0BmY0Rl817H"
      },
      "id": "S0BmY0Rl817H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(temperature=0).bind(functions=pet_openai_functions)"
      ],
      "metadata": {
        "id": "xvgZ9XVI8-22"
      },
      "id": "xvgZ9XVI8-22",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(\"what are three pets names\")"
      ],
      "metadata": {
        "id": "SxGsitru9C7-"
      },
      "id": "SxGsitru9C7-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(\"tell me about pet with id 42\")"
      ],
      "metadata": {
        "id": "qxYHS6ZW9Kqz"
      },
      "id": "qxYHS6ZW9Kqz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Routing**"
      ],
      "metadata": {
        "id": "uOjjKxYV9OOq"
      },
      "id": "uOjjKxYV9OOq"
    },
    {
      "cell_type": "code",
      "source": [
        "functions = [\n",
        "    format_tool_to_openai_function(f) for f in [\n",
        "        search_wikipedia, get_current_temperature\n",
        "    ]\n",
        "]\n",
        "model = ChatOpenAI(temperature=0).bind(functions=functions)"
      ],
      "metadata": {
        "id": "fA6-57o29Ptu"
      },
      "id": "fA6-57o29Ptu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(\"what is the weather in sf right now\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKiHQVG59U0y",
        "outputId": "529d25b4-e173-4e06-a564-de9b7f4da6cc"
      },
      "id": "cKiHQVG59U0y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(\"what is langchain\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-PjbkDq9bD1",
        "outputId": "3648af1e-5b63-41c2-97f7-4b6dccc2d502"
      },
      "id": "W-PjbkDq9bD1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"Langchain\"}', 'name': 'search_wikipedia'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are helpful but sassy assistant\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "])\n",
        "chain = prompt | model"
      ],
      "metadata": {
        "id": "TC9R37uk9exn"
      },
      "id": "TC9R37uk9exn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\": \"what is the weather in sf right now\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNKNOga29g5e",
        "outputId": "3b848635-7681-4792-e86a-a8aba3b484f9"
      },
      "id": "YNKNOga29g5e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\": \"what is langchain\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgoTO9xI9lTs",
        "outputId": "4bc799c9-fb65-47c1-c274-29b5cbcea1e8"
      },
      "id": "bgoTO9xI9lTs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"Langchain\"}', 'name': 'search_wikipedia'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
      ],
      "metadata": {
        "id": "VzEGKt4L9sEL"
      },
      "id": "VzEGKt4L9sEL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
      ],
      "metadata": {
        "id": "B-BATPeG9uvq"
      },
      "id": "B-BATPeG9uvq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\": \"what is the weather in sf right now\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXWrw5hr9wxZ",
        "outputId": "19c2723f-ad53-4e2e-8df3-376673c29d29"
      },
      "id": "eXWrw5hr9wxZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentActionMessageLog(tool='get_current_temperature', tool_input={'latitude': 37.7749, 'longitude': -122.4194}, log=\"\\nInvoking: `get_current_temperature` with `{'latitude': 37.7749, 'longitude': -122.4194}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}}, response_metadata={'finish_reason': 'function_call', 'logprobs': None})])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema.agent import AgentFinish\n",
        "def route(result):\n",
        "    if isinstance(result, AgentFinish):\n",
        "        return result.return_values['output']\n",
        "    else:\n",
        "        tools = {\n",
        "            \"search_wikipedia\": search_wikipedia,\n",
        "            \"get_current_temperature\": get_current_temperature,\n",
        "        }\n",
        "        return tools[result.tool].run(result.tool_input)"
      ],
      "metadata": {
        "id": "a33Hx0P8-Bqg"
      },
      "id": "a33Hx0P8-Bqg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | route"
      ],
      "metadata": {
        "id": "j0YHY445-EXW"
      },
      "id": "j0YHY445-EXW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\": \"What is the weather in san francisco right now?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VF3Em9wB-G_C",
        "outputId": "27b9af61-9ecf-4867-ce20-ea060123b956"
      },
      "id": "VF3Em9wB-G_C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current temperature is 9.6°C'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\": \"What is langchain?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "1r0Wfnto-Il8",
        "outputId": "47b71d23-46b2-4d0d-a2f4-3906b4e12b5a"
      },
      "id": "1r0Wfnto-Il8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: OpenAI\\nSummary: OpenAI is a U.S. based artificial intelligence (AI) research organization founded in December 2015, researching artificial intelligence with the goal of developing \"safe and beneficial\" artificial general intelligence, which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\".\\nAs one of the leading organizations of the AI spring, it has developed several large language models, advanced image generation models, and previously, released open-source models. Its release of ChatGPT has been credited with starting the AI spring.The organization consists of the non-profit OpenAI, Inc. registered in Delaware and its for-profit subsidiary OpenAI Global, LLC. It was founded by Ilya Sutskever, Greg Brockman, Trevor Blackwell, Vicki Cheung, Andrej Karpathy, Durk Kingma, Jessica Livingston, John Schulman, Pamela Vagata, and Wojciech Zaremba, with Sam Altman and Elon Musk serving as the initial Board of Directors members. Microsoft provided OpenAI Global LLC with a $1 billion investment in 2019 and a $10 billion investment in 2023, with a significant portion of the investment in the form of computational resources on Microsoft\\'s Azure cloud service.On November 17, 2023, the board removed Altman as CEO, while Brockman was removed as chairman and then resigned as president. Four days later, both returned after negotiations with the board, and most of the board members resigned. The new initial board included former Salesforce co-CEO Bret Taylor as chairman. It was also announced that Microsoft will have a non-voting board seat.\\n\\nPage: DataStax\\nSummary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"input\": \"hi!\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1Ol7DzUh-Ung",
        "outputId": "e3fca2bf-7c10-48d4-b17a-3c9c8a7cd85c"
      },
      "id": "1Ol7DzUh-Ung",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Well, hello there! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}